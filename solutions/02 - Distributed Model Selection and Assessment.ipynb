{
 "metadata": {
  "name": "02 - Distributed Model Selection and Assessment"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Distributed Model Selection and Assessment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<style>\n",
      "div.input {\n",
      "    width: 105ex; /* about 80 chars + buffer */\n",
      "}\n",
      "div.text_cell {\n",
      "    width: 105ex; /* instead of 100%, */\n",
      "}\n",
      "div.text_cell_render {\n",
      "    /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/\n",
      "    font-family: \"Charis SIL\", serif !important; /* Make non-code text serif. */\n",
      "    line-height: 145% !important; /* added for some line spacing of text. */\n",
      "    width: 105ex !important; /* instead of 'inherit' for shorter lines */\n",
      "}\n",
      "/* Set the size of the headers */\n",
      "div.text_cell_render h1 {\n",
      "    font-size: 18pt;\n",
      "}\n",
      "div.text_cell_render h2 {\n",
      "    font-size: 14pt;\n",
      "}\n",
      ".CodeMirror {\n",
      "     font-family: Consolas, monospace;\n",
      "}\n",
      "</style>\n",
      "\n",
      "Outline of the session:\n",
      "\n",
      "- Introduction to IPython.parallel\n",
      "- Parallel Computation of Learning Curves\n",
      "- Parallel Grid Search and Model Selection\n",
      "- Distributing the Computation on EC2 Spot Instances with StarCluster"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "IPython.parallel, a Primer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section gives a primer on some tools best utilizing computational resources when doing predictive modeling in the Python / NumPy ecosystem namely:\n",
      "\n",
      "- optimal usage of available CPUs and cluster nodes with **`IPython.parallel`**\n",
      "\n",
      "- optimal memory re-use using shared memory between Python processes using **`numpy.memmap`** and **`joblib`**\n",
      "\n",
      "### What is so great about `IPython.parallel`:\n",
      "\n",
      "- Single node multi-CPUs\n",
      "- Multiple node multi-CPUs\n",
      "- Interactive In-memory computing\n",
      "- IPython notebook integration with `%px` and `%%px` magics\n",
      "- Possibility to interactively connect to individual computing processes to launch interactive debugger (`#priceless`)\n",
      "\n",
      "### Let's get started:\n",
      "\n",
      "Go to the \"Cluster\" tab of the notebook and **start a local cluster with 2 engines**. Then come back here:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "dv = client[:]\n",
      "dv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<DirectView [0, 1]>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Sharing Read-only Data between Processes on the Same Host with Memmapping"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parallel Computation of Learning Curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "_ = pl.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.kernel.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      },
      {
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x1039d2b10>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parallel Model Selection and Grid Search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Distributing the Computation on EC2 Spot Instances with StarCluster"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Installation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To provision a cheap transient compute cluster on Amazon EC2, the first step is to register on EC2 with a credit card and put your EC2 credentials as environment variables. For instance under Linux / OSX:\n",
      "\n",
      "    $ export AWS_ACCESS_KEY_ID=XXXXXXXXXXXXXXXXXXXXX\n",
      "    $ export AWS_SECRET_ACCESS_KEY=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "You can put those exports in your `~/.bashrc` to automatically get those credentials loaded in new shell sessions.\n",
      "\n",
      "Then proceed to the installation of StarCluster it-self:\n",
      "\n",
      "    $ pip install StarCluster"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Launching a Cluster"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start a new cluster using the `myclustertemplate` section of the `~/.startcluster/config` file:\n",
      "\n",
      "    $ starcluster start -c myclustertemplate -s 3 mycluster\n",
      "\n",
      "Connect to the master node via ssh:\n",
      "\n",
      "    $ starcluster sshmaster -A -u myuser\n",
      "\n",
      "- The `-A` flag makes it possible to use your local ssh agent to manage your keys: makes it possible to `git clone` / `git push` github repositories from the master node as you would from your local folder.\n",
      "\n",
      "- The StarCluster AMI comes with `tmux` installed by default to make it \n",
      "\n",
      "It is possible to ssh into other cluster nodes from the master using local DNS aliases such as:\n",
      "\n",
      "    [myuser@master]$ ssh node001"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Terminating a Cluster"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once your are done with your computation, don't forget to shutdown the whole cluster and EBS volume so as to only pay for the resources you used.\n",
      "\n",
      "Before doing so, don't forget to backup any result file you would like to keep, by either pushing them to the S3 storage service (recommended for large files that you would want to reuse on EC2 later) or fetching them locally using the `starcluster get` command.\n",
      "\n",
      "The cluster shutdown itself can be achieved with a single command:\n",
      "\n",
      "    $ starcluster terminate mycluster\n",
      "\n",
      "Alternatively to **keep your data** by preserving the EBS volume of attached to the master node, you can do instead:\n",
      "\n",
      "    $ starcluster stop mycluster\n",
      "\n",
      "You can then later restart the same cluster again with the `start` command to automatically remount the EBS volume."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}