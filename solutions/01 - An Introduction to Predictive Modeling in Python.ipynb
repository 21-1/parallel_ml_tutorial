{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "An introduction to Predictive Modeling in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"images/predictive_modeling_data_flow.png\">"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading tabular data from the Titanic kaggle challenge in a pandas Data Frame"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us have a look at the Titanic dataset from the Kaggle Getting Started challenge at:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted\n",
      "\n",
      "We can load the CSV file as a pandas data frame in one line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = pd.read_csv('../datasets/titanic_train.csv')\n",
      "data = pd.read_csv('https://dl.dropboxusercontent.com/u/5743203/data/titanic/titanic_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas data frames have a HTML table representation in the IPython notebook. Let's have a look at the first 5 rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                           Braund, Mr. Owen Harris</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>        A/5 21171</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>         PC 17599</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td>  C85</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>                            Heikkinen, Miss. Laina</td>\n",
        "      <td> female</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> STON/O2. 3101282</td>\n",
        "      <td>  7.9250</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
        "      <td> female</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>           113803</td>\n",
        "      <td> 53.1000</td>\n",
        "      <td> C123</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                          Allen, Mr. William Henry</td>\n",
        "      <td>   male</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>           373450</td>\n",
        "      <td>  8.0500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   PassengerId  Survived  Pclass  \\\n",
        "0            1         0       3   \n",
        "1            2         1       1   \n",
        "2            3         1       3   \n",
        "3            4         1       1   \n",
        "4            5         0       3   \n",
        "\n",
        "                                                Name     Sex  Age  SibSp  \\\n",
        "0                            Braund, Mr. Owen Harris    male   22      1   \n",
        "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
        "2                             Heikkinen, Miss. Laina  female   26      0   \n",
        "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
        "4                           Allen, Mr. William Henry    male   35      0   \n",
        "\n",
        "   Parch            Ticket     Fare Cabin Embarked  \n",
        "0      0         A/5 21171   7.2500   NaN        S  \n",
        "1      0          PC 17599  71.2833   C85        C  \n",
        "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
        "3      0            113803  53.1000  C123        S  \n",
        "4      0            373450   8.0500   NaN        S  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "PassengerId    891\n",
        "Survived       891\n",
        "Pclass         891\n",
        "Name           891\n",
        "Sex            891\n",
        "Age            714\n",
        "SibSp          891\n",
        "Parch          891\n",
        "Ticket         891\n",
        "Fare           891\n",
        "Cabin          204\n",
        "Embarked       889\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data frame has 891 rows. Some passengers have missing information though: in particular Age and Cabin info can be missing. The meaning of the columns is explained on the challenge website:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted/data\n",
      "\n",
      "A data frame can be converted into a numpy array by calling the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[1, 0, 3, ..., 7.25, nan, 'S'],\n",
        "       [2, 1, 1, ..., 71.2833, 'C85', 'C'],\n",
        "       [3, 1, 3, ..., 7.925, nan, 'S'],\n",
        "       ..., \n",
        "       [889, 0, 3, ..., 23.45, nan, 'S'],\n",
        "       [890, 1, 1, ..., 30.0, 'C148', 'C'],\n",
        "       [891, 0, 3, ..., 7.75, nan, 'Q']], dtype=object)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However this cannot be directly fed to a scikit-learn model:\n",
      "\n",
      "\n",
      "- the target variable (survival) is mixed with the input data\n",
      "\n",
      "- some attribute such as unique ids have no predictive values for the task\n",
      "\n",
      "- the values are heterogeneous (string labels for categories, integers and floating point numbers)\n",
      "\n",
      "- some attribute values are missing (nan: \"not a number\")"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicting survival"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of the challenge is to predict whether a passenger has survived from others known attribute. Let us have a look at the `Survived` columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.Survived.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`data.Survived` is an instance of the pandas `Series` class with an integer dtype:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.Survived.__class__.__module__, data.Survived.__class__.__name__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "('pandas.core.series', 'Series')"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `data` object is an instance pandas `DataFrame` class:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.__class__.__module__, data.__class__.__name__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "('pandas.core.frame', 'DataFrame')"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Series` can be seen as homegeneous, 1D columns. `DataFrame` instances are heterogenous collections of columns with the same length.\n",
      "\n",
      "The original data frame can be aggregated by counting rows for each possible value of the `Survived` column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.groupby('Survived').count()['Survived']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "Survived\n",
        "0           549\n",
        "1           342\n",
        "Name: Survived, dtype: int64"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this the subset of the full passengers list, about 2/3 perished in the event. So if we are to build a predictive model from this data, a baseline model to compare the performance to would be to always predict death. Such a constant model would reach around 62% predictive accuracy (which is higher than predicting at random):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(data.Survived == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.61616161616161613"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas `Series` instances can be converted to regular 1D numpy arrays by using the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = data.Survived.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "numpy.ndarray"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([0, 1, 1, 1, 0])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training a predictive model on numerical features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` estimators all work with homegeneous numerical feature descriptors passed as a numpy array. Therefore passing the raw data frame will not work out of the box.\n",
      "\n",
      "Let us start simple and build a first model that only uses readily available numerical features as input, namely `data.Fare`, `data.Pclass` and `data.Age`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
      "numerical_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately some passengers do not have age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       714\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use pandas `fillna` method to input the median age for those passengers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "median_features = numerical_features.dropna().median()\n",
      "median_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "Fare      15.7417\n",
        "Pclass     2.0000\n",
        "Age       28.0000\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features = numerical_features.fillna(median_features)\n",
      "imputed_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       891\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the data frame is clean, we can convert it into an homogeneous numpy array of floating point values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array = imputed_features.values\n",
      "features_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "array([[  7.25  ,   3.    ,  22.    ],\n",
        "       [ 71.2833,   1.    ,  38.    ],\n",
        "       [  7.925 ,   3.    ,  26.    ],\n",
        "       ..., \n",
        "       [ 23.45  ,   3.    ,  28.    ],\n",
        "       [ 30.    ,   1.    ,  26.    ],\n",
        "       [  7.75  ,   3.    ,  32.    ]])"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take the 80% of the data for training a first model and keep 20% for computing is generalization score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(712, 3)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "(179, 3)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "(712,)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "(179,)"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a simple model from sklearn, namely `LogisticRegression`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "lr = LogisticRegression(C=1)\n",
      "lr.fit(features_train, target_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted = lr.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "accuracy_score(target_test, target_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This first model has around 73% accuracy: this is better than our baselines that always predicts death."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model evaluation and interpretation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interpreting linear model weights"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `coef_` attribute of a fitted linear model such as `LogisticRegression` holds the weights of each features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = numerical_features.columns.values\n",
      "feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "array(['Fare', 'Pclass', 'Age'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "array([[ 0.0043996 , -0.80916725, -0.03348064]])"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(3)\n",
      "plt.bar(x, lr.coef_.ravel())\n",
      "_ = plt.xticks(x + 0.5, feature_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10908a950>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, survival is slightly positively linked with Fare (the higher the fare, the higher the likelyhood the model will predict survival) while passenger from class 1 and lower ages are predictd"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Alternative evaluation metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic Regression is a probabilistic models: instead of just predicting a binary outcome (survived or not) given the input features it can also estimates the posterior probability of the outcome given the input features using the `predict_proba` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted_proba = lr.predict_proba(features_test)\n",
      "target_predicted_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "array([[ 0.75263264,  0.24736736],\n",
        "       [ 0.75824771,  0.24175229],\n",
        "       [ 0.58542437,  0.41457563],\n",
        "       [ 0.25224882,  0.74775118],\n",
        "       [ 0.75817844,  0.24182156]])"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default the decision threshold is 0.5: if we vary the decision threshold from 0 to 1 we could generate a family of binary classifier models that address all the possible trade offs between false positive and false negative prediction errors.\n",
      "\n",
      "We can summarize the performance of a binary classifier for all the possible thresholds by plotting the ROC curve and quantifying the Area under the ROC curve:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(target_test, target_predicted_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(target_test, target_predicted_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEEQkvwB/H8HKGV66J8AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10908ac10>"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here the area under ROC curve is 0.756 which is very similar to the accuracy (0.732). However the ROC-AUC score of a random model is expected to 0.5 on average while the accuracy score of a random model depends on the class imbalance of the data. ROC-AUC can be seen as a way to callibrate the predictive accuracy of a model against class imbalance.\n",
      "\n",
      "It is possible to see the details of the false positive and false negative errors by computing the confusion matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "print(confusion_matrix(target_test, target_predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[98 12]\n",
        " [36 33]]\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way to quantify the quality of a binary classifier on imbalanced data is to compute the precision, recall and f1-score of a model (at the default fixed decision threshold of 0.5)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.73      0.89      0.80       110\n",
        "    survived       0.73      0.48      0.58        69\n",
        "\n",
        " avg / total       0.73      0.73      0.72       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross-validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We previously decided to randomly split the data to evaluate the model on 20% of held-out data. However the location randomness of the split might have a significant impact in the estimated accuracy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)\n",
      "\n",
      "lr.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=1)\n",
      "\n",
      "lr.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "0.67039106145251393"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=2)\n",
      "\n",
      "lr.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "0.66480446927374304"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So instead of using a single train / test split, we can use a group of them and compute the min, max and mean scores as an estimation of the real test score while not underestimating the variability:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = cross_val_score(lr, features_array, target, cv=5)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "array([ 0.68715084,  0.69662921,  0.69662921,  0.67977528,  0.74157303])"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "(0.6797752808988764, 0.7003515159123721, 0.7415730337078652)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`cross_val_score` reports accuracy by default be it can also be used to report other performance metrics such as ROC-AUC or f1-score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(lr, features_array, target, cv=5,\n",
      "                         scoring='roc_auc')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "(0.6510695187165777, 0.72530175046411949, 0.78147852679165031)"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Compute cross-validated scores for other classification metrics.\n",
      "\n",
      "- Change the number of cross-validation folds between 3 and 10: what is the impact on the mean score? on the processing time?\n",
      "\n",
      "Hints:\n",
      "\n",
      "The list of classification metrics is available in the online documentation:\n",
      "\n",
      "  http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\n",
      "  \n",
      "You can use the `%%time` cell magic on the first line of an IPython cell to measure the time of the execution of the cell. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(lr, features_array, target, cv=5,\n",
      "                         scoring='f1')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "(0.5, 0.51922740966026193, 0.56603773584905659)"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "scores = cross_val_score(lr, features_array, target, cv=3,\n",
      "                         scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.6902356902356902, 0.70707070707070707, 0.72727272727272729)\n",
        "CPU times: user 7.41 ms, sys: 1.12 ms, total: 8.53 ms\n",
        "Wall time: 7.41 ms\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "scores = cross_val_score(lr, features_array, target, cv=5,\n",
      "                         scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.6797752808988764, 0.7003515159123721, 0.7415730337078652)\n",
        "CPU times: user 17.3 ms, sys: 702 \u00b5s, total: 18 ms\n",
        "Wall time: 17.4 ms\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "scores = cross_val_score(lr, features_array, target, cv=10,\n",
      "                         scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.651685393258427, 0.70037453183520593, 0.7528089887640449)\n",
        "CPU times: user 27.6 ms, sys: 755 \u00b5s, total: 28.3 ms\n",
        "Wall time: 27.5 ms\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature engineering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = pd.concat([data.get(['Fare', 'Age']),\n",
      "                      pd.get_dummies(data.Pclass, prefix='Pclass'),\n",
      "                      pd.get_dummies(data.Sex, prefix='Sex'),\n",
      "                      pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
      "                     axis=1)\n",
      "features = features.drop('Sex_male', 1)\n",
      "features = features.fillna(features.dropna().median())\n",
      "features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Age</th>\n",
        "      <th>Pclass_1</th>\n",
        "      <th>Pclass_2</th>\n",
        "      <th>Pclass_3</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "      Fare  Age  Pclass_1  Pclass_2  Pclass_3  Sex_female  Embarked_C  \\\n",
        "0   7.2500   22         0         0         1           0           0   \n",
        "1  71.2833   38         1         0         0           1           1   \n",
        "2   7.9250   26         0         0         1           1           0   \n",
        "3  53.1000   35         1         0         0           1           0   \n",
        "4   8.0500   35         0         0         1           0           0   \n",
        "\n",
        "   Embarked_Q  Embarked_S  \n",
        "0           0           1  \n",
        "1           0           0  \n",
        "2           0           1  \n",
        "3           0           1  \n",
        "4           0           1  "
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "lr = LogisticRegression(C=1)\n",
      "scores = cross_val_score(lr, features, target, cv=5, scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.7528089887640449, 0.78789780930261755, 0.8202247191011236)\n",
        "CPU times: user 17.1 ms, sys: 1.02 ms, total: 18.1 ms\n",
        "Wall time: 17.3 ms\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "scores = cross_val_score(rf, features, target, cv=5, n_jobs=4, scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.7865168539325843, 0.82827192266649929, 0.8539325842696629)\n",
        "CPU times: user 12.8 ms, sys: 17.1 ms, total: 29.8 ms\n",
        "Wall time: 630 ms\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
      "                                subsample=.8, max_features=.5)\n",
      "scores = cross_val_score(gb, features, target, cv=5, n_jobs=2, scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.7808988764044944, 0.81928943569141932, 0.848314606741573)\n",
        "CPU times: user 10.7 ms, sys: 13.7 ms, total: 24.4 ms\n",
        "Wall time: 521 ms\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Automated parameter tuning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "params = {\n",
      "    'learning_rate': [0.05, 0.1, 0.5],\n",
      "    'max_features': [0.5, 1],\n",
      "    'max_depth': [3, 4, 5],\n",
      "}\n",
      "gs = GridSearchCV(gb, params, cv=5, scoring='roc_auc', n_jobs=4, refit=False).fit(features, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 67.7 ms, sys: 26.8 ms, total: 94.6 ms\n",
        "Wall time: 7.19 s\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "[mean: 0.86755, std: 0.03011, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 3},\n",
        " mean: 0.86000, std: 0.03727, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 3},\n",
        " mean: 0.86871, std: 0.02843, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 4},\n",
        " mean: 0.86949, std: 0.03155, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 4},\n",
        " mean: 0.87427, std: 0.02658, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 5},\n",
        " mean: 0.86773, std: 0.03007, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 5},\n",
        " mean: 0.87441, std: 0.03047, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 3},\n",
        " mean: 0.86337, std: 0.03262, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 3},\n",
        " mean: 0.87092, std: 0.02912, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 4},\n",
        " mean: 0.86888, std: 0.03296, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 4},\n",
        " mean: 0.86780, std: 0.02633, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 5},\n",
        " mean: 0.87186, std: 0.02633, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 5},\n",
        " mean: 0.85134, std: 0.03105, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 3},\n",
        " mean: 0.85745, std: 0.03801, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 3},\n",
        " mean: 0.84230, std: 0.04073, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 4},\n",
        " mean: 0.84096, std: 0.04091, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 4},\n",
        " mean: 0.85216, std: 0.02576, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 5},\n",
        " mean: 0.83927, std: 0.03240, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 5}]"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "0.87440973341447914"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 0.5}"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Further integrating sklearn and pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper tool for better sklearn / pandas integration: https://github.com/paulgb/sklearn-pandas"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}