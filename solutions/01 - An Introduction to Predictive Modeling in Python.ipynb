{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "An introduction to Predictive Modeling in Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"images/predictive_modeling_data_flow.png\">"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading tabular data from the Titanic kaggle challenge in a pandas Data Frame"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us have a look at the Titanic dataset from the Kaggle Getting Started challenge at:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted\n",
      "\n",
      "We can load the CSV file as a pandas data frame in one line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = pd.read_csv('../datasets/titanic_train.csv')\n",
      "data = pd.read_csv('https://dl.dropboxusercontent.com/u/5743203/data/titanic/titanic_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas data frames have a HTML table representation in the IPython notebook. Let's have a look at the first 5 rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                           Braund, Mr. Owen Harris</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>        A/5 21171</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>         PC 17599</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td>  C85</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>                            Heikkinen, Miss. Laina</td>\n",
        "      <td> female</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> STON/O2. 3101282</td>\n",
        "      <td>  7.9250</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
        "      <td> female</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>           113803</td>\n",
        "      <td> 53.1000</td>\n",
        "      <td> C123</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                          Allen, Mr. William Henry</td>\n",
        "      <td>   male</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>           373450</td>\n",
        "      <td>  8.0500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 12 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "   PassengerId  Survived  Pclass  \\\n",
        "0            1         0       3   \n",
        "1            2         1       1   \n",
        "2            3         1       3   \n",
        "3            4         1       1   \n",
        "4            5         0       3   \n",
        "\n",
        "                                                Name     Sex  Age  SibSp  \\\n",
        "0                            Braund, Mr. Owen Harris    male   22      1   \n",
        "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
        "2                             Heikkinen, Miss. Laina  female   26      0   \n",
        "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
        "4                           Allen, Mr. William Henry    male   35      0   \n",
        "\n",
        "   Parch            Ticket     Fare Cabin Embarked  \n",
        "0      0         A/5 21171   7.2500   NaN        S  \n",
        "1      0          PC 17599  71.2833   C85        C  \n",
        "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
        "3      0            113803  53.1000  C123        S  \n",
        "4      0            373450   8.0500   NaN        S  \n",
        "\n",
        "[5 rows x 12 columns]"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "PassengerId    891\n",
        "Survived       891\n",
        "Pclass         891\n",
        "Name           891\n",
        "Sex            891\n",
        "Age            714\n",
        "SibSp          891\n",
        "Parch          891\n",
        "Ticket         891\n",
        "Fare           891\n",
        "Cabin          204\n",
        "Embarked       889\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data frame has 891 rows. Some passengers have missing information though: in particular Age and Cabin info can be missing. The meaning of the columns is explained on the challenge website:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted/data\n",
      "\n",
      "A data frame can be converted into a numpy array by calling the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "array([[1, 0, 3, ..., 7.25, nan, 'S'],\n",
        "       [2, 1, 1, ..., 71.2833, 'C85', 'C'],\n",
        "       [3, 1, 3, ..., 7.925, nan, 'S'],\n",
        "       ..., \n",
        "       [889, 0, 3, ..., 23.45, nan, 'S'],\n",
        "       [890, 1, 1, ..., 30.0, 'C148', 'C'],\n",
        "       [891, 0, 3, ..., 7.75, nan, 'Q']], dtype=object)"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However this cannot be directly fed to a scikit-learn model:\n",
      "\n",
      "\n",
      "- the target variable (survival) is mixed with the input data\n",
      "\n",
      "- some attribute such as unique ids have no predictive values for the task\n",
      "\n",
      "- the values are heterogeneous (string labels for categories, integers and floating point numbers)\n",
      "\n",
      "- some attribute values are missing (nan: \"not a number\")"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicting survival"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of the challenge is to predict whether a passenger has survived from others known attribute. Let us have a look at the `Survived` columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.Survived.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`data.Survived` is an instance of the pandas `Series` class with an integer dtype:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.Survived.__class__.__module__, data.Survived.__class__.__name__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "('pandas.core.series', 'Series')"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `data` object is an instance pandas `DataFrame` class:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.__class__.__module__, data.__class__.__name__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "('pandas.core.frame', 'DataFrame')"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Series` can be seen as homegeneous, 1D columns. `DataFrame` instances are heterogenous collections of columns with the same length.\n",
      "\n",
      "The original data frame can be aggregated by counting rows for each possible value of the `Survived` column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.groupby('Survived').count()['Survived']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "Survived\n",
        "0           549\n",
        "1           342\n",
        "Name: Survived, dtype: int64"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this the subset of the full passengers list, about 2/3 perished in the event. So if we are to build a predictive model from this data, a baseline model to compare the performance to would be to always predict death. Such a constant model would reach around 62% predictive accuracy (which is higher than predicting at random):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(data.Survived == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "0.61616161616161613"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas `Series` instances can be converted to regular 1D numpy arrays by using the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = data.Survived.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "numpy.ndarray"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 326,
       "text": [
        "array([0, 1, 1, 1, 0])"
       ]
      }
     ],
     "prompt_number": 326
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training a predictive model on numerical features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` estimators all work with homegeneous numerical feature descriptors passed as a numpy array. Therefore passing the raw data frame will not work out of the box.\n",
      "\n",
      "Let us start simple and build a first model that only uses readily available numerical features as input, namely `data.Fare`, `data.Pclass` and `data.Age`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
      "numerical_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 234,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35\n",
        "\n",
        "[5 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 234
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately some passengers do not have age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 241,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       714\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use pandas `fillna` method to input the median age for those passengers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "median_features = numerical_features.dropna().median()\n",
      "median_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 242,
       "text": [
        "Fare      15.7417\n",
        "Pclass     2.0000\n",
        "Age       28.0000\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features = numerical_features.fillna(median_features)\n",
      "imputed_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 244,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       891\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 273,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35\n",
        "\n",
        "[5 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 273
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the data frame is clean, we can convert it into an homogeneous numpy array of floating point values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array = imputed_features.values\n",
      "features_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 272,
       "text": [
        "array([[  7.25  ,   3.    ,  22.    ],\n",
        "       [ 71.2833,   1.    ,  38.    ],\n",
        "       [  7.925 ,   3.    ,  26.    ],\n",
        "       ..., \n",
        "       [ 23.45  ,   3.    ,  28.    ],\n",
        "       [ 30.    ,   1.    ,  26.    ],\n",
        "       [  7.75  ,   3.    ,  32.    ]])"
       ]
      }
     ],
     "prompt_number": 272
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take the 80% of the data for training a first model and keep 20% for computing is generalization score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 293,
       "text": [
        "(712, 3)"
       ]
      }
     ],
     "prompt_number": 293
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 294,
       "text": [
        "(179, 3)"
       ]
      }
     ],
     "prompt_number": 294
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 295,
       "text": [
        "(712,)"
       ]
      }
     ],
     "prompt_number": 295
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 296,
       "text": [
        "(179,)"
       ]
      }
     ],
     "prompt_number": 296
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a simple model from sklearn, namely `LogisticRegression`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "lr = LogisticRegression(C=1)\n",
      "lr.fit(features_train, target_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 297,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted = lr.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "accuracy_score(target_test, target_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 299,
       "text": [
        "0.71508379888268159"
       ]
      }
     ],
     "prompt_number": 299
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This first model has around 71% accuracy: this is better than our baselines that always predicts death."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model evaluation and interpretation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interpreting linear model weights"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `coef_` attribute of a fitted linear model such as `LogisticRegression` holds the weights of each features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = numerical_features.columns.values\n",
      "feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 338,
       "text": [
        "array(['Fare', 'Pclass', 'Age'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 338
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 337,
       "text": [
        "array([[ 0.00342909, -0.90651639, -0.02827781]])"
       ]
      }
     ],
     "prompt_number": 337
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(3)\n",
      "plt.bar(x, lr.coef_.ravel())\n",
      "_ = plt.xticks(x + 0.5, feature_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1111c8a90>"
       ]
      }
     ],
     "prompt_number": 344
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, survival is slightly positively linked with Fare (the higher the fare, the higher the likelyhood the model will predict survival) while passenger from class 1 and lower ages are predictd"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Alternative evaluation metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic Regression is a probabilistic models: instead of just predicting a binary outcome (survived or not) given the input features it can also estimates the posterior probability of the outcome given the input features using the `predict_proba` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted_proba = lr.predict_proba(features_test)\n",
      "target_predicted_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 302,
       "text": [
        "array([[ 0.52187213,  0.47812787],\n",
        "       [ 0.76362642,  0.23637358],\n",
        "       [ 0.24682367,  0.75317633],\n",
        "       [ 0.75466399,  0.24533601],\n",
        "       [ 0.53598956,  0.46401044]])"
       ]
      }
     ],
     "prompt_number": 302
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default the decision threshold is 0.5: if we vary the decision threshold from 0 to 1 we could generate a family of binary classifier models that address all the possible trade offs between false positive and false negative prediction errors.\n",
      "\n",
      "We can summarize the performance of a binary classifier for all the possible thresholds by plotting the ROC curve and quantifying the Area under the ROC curve:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curves(target_test, target_predicted_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(target_test, target_predicted_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBu8AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x110f67250>"
       ]
      }
     ],
     "prompt_number": 325
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here the area under ROC curve is 0.710 which is very similar to the accuracy (0.715). However the ROC-AUC score of a random model is expected to 0.5 on average while the accuracy score of a random model depends on the class imbalance of the data. ROC-AUC can be seen as a way to callibrate the predictive accuracy of a model against class imbalance.\n",
      "\n",
      "It is possible to see the details of the false positive and false negative errors by computing the confusion matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "print(confusion_matrix(target_test, target_predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[94 19]\n",
        " [32 34]]\n"
       ]
      }
     ],
     "prompt_number": 321
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way to quantify the quality of a binary classifier on imbalanced data is to compute the precision, recall and f1-score of a model (at the default fixed decision threshold of 0.5)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.75      0.83      0.79       113\n",
        "    survived       0.64      0.52      0.57        66\n",
        "\n",
        " avg / total       0.71      0.72      0.71       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 320
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross-validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We previously decided to randomly split the data to evaluate the model on 20% of held-out data. However the location randomness of the split might have a significant impact in the estimated accuracy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)\n",
      "\n",
      "lr.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 347,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=1)\n",
      "\n",
      "lr.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 348,
       "text": [
        "0.67039106145251393"
       ]
      }
     ],
     "prompt_number": 348
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=2)\n",
      "\n",
      "lr.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 349,
       "text": [
        "0.66480446927374304"
       ]
      }
     ],
     "prompt_number": 349
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So instead of using a single train / test split, we can use a group of them and compute the min, max and mean scores as an estimation of the real test score while not underestimating the variability:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = cross_val_score(lr, features_array, target, cv=5)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 384,
       "text": [
        "array([ 0.63128492,  0.68715084,  0.70224719,  0.73033708,  0.71751412])"
       ]
      }
     ],
     "prompt_number": 384
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 385,
       "text": [
        "(0.63128491620111726, 0.69370682962933028, 0.7303370786516854)"
       ]
      }
     ],
     "prompt_number": 385
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`cross_val_score` reports accuracy by default be it can also be used to report other performance metrics such as ROC-AUC or f1-score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(lr, features_array, target, cv=5,\n",
      "                         scoring='roc_auc')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 386,
       "text": [
        "(0.61093544137022393, 0.72123181651091728, 0.78776737967914434)"
       ]
      }
     ],
     "prompt_number": 386
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Compute cross-validate scores for other classification metrics\n",
      "\n",
      "- Change the number of cross-validation folds between 3 and 10: what is the impact on the mean score? on the processing time?\n",
      "\n",
      "Hints:\n",
      "\n",
      "The list of classification metrics is available in the online documentation:\n",
      "\n",
      "  http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\n",
      "  \n",
      "You can use the `%%time` cell magic on the first line of an IPython cell to measure the time of the execution of the cell. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(lr, features_array, target, cv=5,\n",
      "                         scoring='f1')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 387,
       "text": [
        "(0.3888888888888889, 0.50492363595071821, 0.56140350877192968)"
       ]
      }
     ],
     "prompt_number": 387
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "scores = cross_val_score(lr, features_array, target, cv=3,\n",
      "                         scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.65993265993265993, 0.69360269360269367, 0.72053872053872059)\n",
        "CPU times: user 9.37 ms, sys: 969 \u00b5s, total: 10.3 ms\n",
        "Wall time: 9.28 ms\n"
       ]
      }
     ],
     "prompt_number": 388
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "scores = cross_val_score(lr, features_array, target, cv=5,\n",
      "                         scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.63128491620111726, 0.69370682962933028, 0.7303370786516854)\n",
        "CPU times: user 14.2 ms, sys: 1.36 ms, total: 15.6 ms\n",
        "Wall time: 14.2 ms\n"
       ]
      }
     ],
     "prompt_number": 389
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "scores = cross_val_score(lr, features_array, target, cv=10,\n",
      "                         scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.62222222222222223, 0.69827006015208259, 0.7528089887640449)\n",
        "CPU times: user 29.9 ms, sys: 1.23 ms, total: 31.1 ms\n",
        "Wall time: 30.1 ms\n"
       ]
      }
     ],
     "prompt_number": 390
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature engineering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = pd.concat([data.get(['Fare', 'Age']),\n",
      "                      pd.get_dummies(data.Pclass, prefix='Pclass'),\n",
      "                      pd.get_dummies(data.Sex, prefix='Sex'),\n",
      "                      pd.get_dummies(data.Embarked, dummy_na=True, prefix='Embarked')],\n",
      "                     axis=1)\n",
      "features = features.drop('Sex_male', 1)\n",
      "features = features.fillna(features.dropna().median())\n",
      "features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Age</th>\n",
        "      <th>Pclass_1</th>\n",
        "      <th>Pclass_2</th>\n",
        "      <th>Pclass_3</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "      <th>Embarked_nan</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 10 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 262,
       "text": [
        "      Fare  Age  Pclass_1  Pclass_2  Pclass_3  Sex_female  Embarked_C  \\\n",
        "0   7.2500   22         0         0         1           0           0   \n",
        "1  71.2833   38         1         0         0           1           1   \n",
        "2   7.9250   26         0         0         1           1           0   \n",
        "3  53.1000   35         1         0         0           1           0   \n",
        "4   8.0500   35         0         0         1           0           0   \n",
        "\n",
        "   Embarked_Q  Embarked_S  Embarked_nan  \n",
        "0           0           1             0  \n",
        "1           0           0             0  \n",
        "2           0           1             0  \n",
        "3           0           1             0  \n",
        "4           0           1             0  \n",
        "\n",
        "[5 rows x 10 columns]"
       ]
      }
     ],
     "prompt_number": 262
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "lr = LogisticRegression(C=1)\n",
      "scores = cross_val_score(lr, features, target, cv=5, n_jobs=2, scoring='accuracy')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 268,
       "text": [
        "(0.7696629213483146, 0.79011106158018329, 0.82122905027932958)"
       ]
      }
     ],
     "prompt_number": 268
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "scores = cross_val_score(rf, features, target, cv=5, n_jobs=2, scoring='accuracy')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 269,
       "text": [
        "(0.77653631284916202, 0.80139123983478178, 0.8258426966292135)"
       ]
      }
     ],
     "prompt_number": 269
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
      "                                subsample=.8, max_features=.5)\n",
      "scores = cross_val_score(gb, features, target, cv=5, n_jobs=2, scoring='accuracy')\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.7988826815642458, 0.82385722751399304, 0.8539325842696629)\n",
        "CPU times: user 83.8 ms, sys: 16.8 ms, total: 101 ms\n",
        "Wall time: 588 ms\n"
       ]
      }
     ],
     "prompt_number": 393
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Automated parameter tuning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "params = {\n",
      "    'learning_rate': [0.05, 0.1, 0.5],\n",
      "    'max_features': [0.5, 1],\n",
      "    'max_depth': [3, 4, 5],\n",
      "}\n",
      "gs = GridSearchCV(gb, params, cv=5, scoring='roc_auc', n_jobs=4, refit=False).fit(features, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 256 ms, sys: 30.1 ms, total: 286 ms\n",
        "Wall time: 5.72 s\n"
       ]
      }
     ],
     "prompt_number": 370
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 371,
       "text": [
        "[mean: 0.86965, std: 0.02652, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 3},\n",
        " mean: 0.85780, std: 0.02010, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 3},\n",
        " mean: 0.86826, std: 0.02768, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 4},\n",
        " mean: 0.86550, std: 0.02039, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 4},\n",
        " mean: 0.87280, std: 0.02865, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 5},\n",
        " mean: 0.87127, std: 0.02826, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 5},\n",
        " mean: 0.87509, std: 0.02969, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 3},\n",
        " mean: 0.86424, std: 0.02473, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 3},\n",
        " mean: 0.87296, std: 0.02260, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 4},\n",
        " mean: 0.86880, std: 0.02622, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 4},\n",
        " mean: 0.87870, std: 0.02277, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 5},\n",
        " mean: 0.86848, std: 0.02645, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 5},\n",
        " mean: 0.86436, std: 0.02684, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 3},\n",
        " mean: 0.86027, std: 0.02894, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 3},\n",
        " mean: 0.85728, std: 0.02951, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 4},\n",
        " mean: 0.85903, std: 0.03036, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 4},\n",
        " mean: 0.84774, std: 0.01221, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 5},\n",
        " mean: 0.84653, std: 0.02175, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 5}]"
       ]
      }
     ],
     "prompt_number": 371
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 372,
       "text": [
        "0.8787000965258529"
       ]
      }
     ],
     "prompt_number": 372
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 373,
       "text": [
        "{'learning_rate': 0.1, 'max_depth': 5, 'max_features': 0.5}"
       ]
      }
     ],
     "prompt_number": 373
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Further integrating sklearn and pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper tool for better sklearn / pandas integration: https://github.com/paulgb/sklearn-pandas"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}