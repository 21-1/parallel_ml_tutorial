{
 "metadata": {
  "name": "01 - Model Selection and Assessment"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Model Selection and Assessment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "<style>\n",
      "div.input {\n",
      "    width: 105ex; /* about 80 chars + buffer */\n",
      "}\n",
      "div.text_cell {\n",
      "    width: 105ex; /* instead of 100%, */\n",
      "}\n",
      "div.text_cell_render {\n",
      "    /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/\n",
      "    font-family: \"Charis SIL\", serif !important; /* Make non-code text serif. */\n",
      "    line-height: 145% !important; /* added for some line spacing of text. */\n",
      "    width: 105ex !important; /* instead of 'inherit' for shorter lines */\n",
      "}\n",
      "/* Set the size of the headers */\n",
      "div.text_cell_render h1 {\n",
      "    font-size: 18pt;\n",
      "}\n",
      "div.text_cell_render h2 {\n",
      "    font-size: 14pt;\n",
      "}\n",
      ".CodeMirror {\n",
      "     font-family: Consolas, monospace;\n",
      "}\n",
      "</style>\n",
      "\n",
      "Outline of the session:\n",
      "\n",
      "- Model performance evaluation and **detection of overfitting with Cross-Validation**\n",
      "- **Hyper parameter tuning** and model selection with Grid Search\n",
      "- Error analysis with **learning curves** and the **Bias-Variance trade-off**\n",
      "- Overfitting via Model Selection and the **Development / Evaluation set split**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "\n",
      "pl.rcParams['figure.figsize'] = 10, 7.5\n",
      "pl.gray()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.kernel.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      },
      {
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x10ccb5e10>"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The Hand Written Digits Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's load a simple dataset of 8x8 gray level images of handwritten digits (bundled in the sklearn source code):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()\n",
      "print(digits.DESCR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Optical Recognition of Handwritten Digits Data Set\n",
        "\n",
        "Notes\n",
        "-----\n",
        "Data Set Characteristics:\n",
        "    :Number of Instances: 5620\n",
        "    :Number of Attributes: 64\n",
        "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
        "    :Missing Attribute Values: None\n",
        "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
        "    :Date: July; 1998\n",
        "\n",
        "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
        "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
        "\n",
        "The data set contains images of hand-written digits: 10 classes where\n",
        "each class refers to a digit.\n",
        "\n",
        "Preprocessing programs made available by NIST were used to extract\n",
        "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
        "total of 43 people, 30 contributed to the training set and different 13\n",
        "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
        "4x4 and the number of on pixels are counted in each block. This generates\n",
        "an input matrix of 8x8 where each element is an integer in the range\n",
        "0..16. This reduces dimensionality and gives invariance to small\n",
        "distortions.\n",
        "\n",
        "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
        "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
        "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
        "1994.\n",
        "\n",
        "References\n",
        "----------\n",
        "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
        "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
        "    Graduate Studies in Science and Engineering, Bogazici University.\n",
        "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
        "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
        "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
        "    Electrical and Electronic Engineering Nanyang Technological University.\n",
        "    2005.\n",
        "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
        "    Algorithm. NIPS. 2000.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = digits.data, digits.target\n",
      "print(\"data shape: %r, target shape: %r\" % (X.shape, y.shape))\n",
      "print(\"classes: %r\" % list(np.unique(y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data shape: (1797, 64), target shape: (1797,)\n",
        "classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples, n_features = X.shape\n",
      "print(\"n_samples=%d\" % n_samples)\n",
      "print(\"n_features=%d\" % n_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "n_samples=1797\n",
        "n_features=64\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, j in enumerate(np.random.permutation(X.shape[0])[:5]):\n",
      "    pl.subplot(1, 5, (i + 1))\n",
      "    pl.imshow(X[j].reshape((8, 8)), interpolation='nearest')\n",
      "    pl.title(\"true class: %d\" % y[j])\n",
      "    pl.xticks(()), pl.yticks(())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAB9CAYAAACmlLl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB89FMEcqbsiiAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10e4cd450>"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overfitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overfitting is the problem of learning the training data by heart and being unable to generalize by making correct predictions on data samples unseen while training."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To illustrate this, let's train a Support Vector Machine naively on the digits dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "SVC().fit(X, y).score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Did we really learn a perfect model that can recognize the correct digit class 100% of the time? **Without new data it's impossible to tell.**\n",
      "\n",
      "Let's start again and split the dataset into two random, non overlapping subsets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(\n",
      "    X, y, test_size=0.25, random_state=0)\n",
      "\n",
      "print(\"train data shape: %r, train target shape: %r\"\n",
      "      % (X_train.shape, y_train.shape))\n",
      "print(\"test data shape: %r, test target shape: %r\"\n",
      "      % (X_test.shape, y_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train data shape: (1347, 64), train target shape: (1347,)\n",
        "test data shape: (450, 64), test target shape: (450,)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's retrain a new model on the first subset call the **training set**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC(kernel='rbf').fit(X_train, y_train)\n",
      "train_score = svc.score(X_train, y_train) \n",
      "train_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now compute the performance of the model on new, held out data from the **test set**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_score = svc.score(X_test, y_test)\n",
      "test_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.48666666666666669"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This score is clearly not as good as expected! The model cannot generalize so well to new, unseen data.\n",
      "\n",
      "- Whenever the **test** data score is **not as good as** the **train** score the model is **overfitting**\n",
      "\n",
      "- Whenever the **train score is not close to 100%** accuracy the model is **underfitting**\n",
      "\n",
      "Ideally **we want to neither overfit nor underfit**: `test_score ~= train_score ~= 1.0`. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The previous example failed to generalized well to test data because we naively used the default parameters of the `SVC` class:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, shrinking=True, tol=0.001,\n",
        "  verbose=False)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try again with another parameterization:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc_2 = SVC(kernel='rbf', C=100, gamma=0.001).fit(X_train, y_train)\n",
      "svc_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=0.001, kernel='rbf', max_iter=-1, probability=False,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc_2.score(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc_2.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "0.99333333333333329"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case the model is almost perfectly able to generalize, at least according to our random train, test split."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import ShuffleSplit\n",
      "\n",
      "cv = ShuffleSplit(n_samples, n_iter=3, test_size=0.1,\n",
      "    random_state=0)\n",
      "\n",
      "for cv_index, (train, test) in enumerate(cv):\n",
      "    print(\"# Cross Validation Iteration #%d\" % cv_index)\n",
      "    print(\"train indices: {0}...\".format(train[:10]))\n",
      "    print(\"test indices: {0}...\".format(test[:10]))\n",
      "    \n",
      "    svc = SVC(kernel=\"rbf\", C=1, gamma=0.001).fit(X[train], y[train])\n",
      "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
      "        svc.score(X[train], y[train]), svc.score(X[test], y[test])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Cross Validation Iteration #0\n",
        "train indices: [ 353    5   58 1349 1025  575 1074 1110 1745  689]...\n",
        "test indices: [1081 1707  927  713  262  182  303  895  933 1266]...\n",
        "train score: 0.999, test score: 0.989\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "# Cross Validation Iteration #1\n",
        "train indices: [1336  608  977   22  526 1587 1130  569 1481  962]...\n",
        "test indices: [1014  755 1633  117  181  501  948 1076   45  659]...\n",
        "train score: 0.998, test score: 0.994\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "# Cross Validation Iteration #2\n",
        "train indices: [ 451  409  911 1551  133  691 1306  111  852  825]...\n",
        "test indices: [ 795  697  655  573  412  743  635  851 1466 1383]...\n",
        "train score: 0.999, test score: 0.994\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "# TODO n_jobs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import sem\n",
      "\n",
      "def mean_with_ci(scores):\n",
      "    \"\"\"Compute the mean score and standard 95% Confidence Interval\n",
      "\n",
      "    Assume that the distribution of the scores is normal which\n",
      "    is probably not true when the mean is close to an upper or\n",
      "    lower bound.\n",
      "\n",
      "    For better CI evaluation, use scikits.bootstrap.\n",
      "    \"\"\"\n",
      "    scores = np.asarray(scores).ravel()\n",
      "    m, s = np.mean(scores), sem(scores)\n",
      "    ci_width = 2 * 1.96 * s\n",
      "    return m, ci_width\n",
      "\n",
      "def mean_score(scores):\n",
      "    \"\"\"Print the mean score and standard 95% Confidence Interval\"\"\"\n",
      "    m, ci_width = mean_with_ci(scores)\n",
      "    return (\"Mean score: {0:.3f} [{1:.3f} - {2:.3f}]\").format(\n",
      "        m, m - ci_width / 2, m + ci_width / 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise:** \n",
      "\n",
      "- Perform 50 iterations of cross validation with randomly sampled folds of 500 training samples and 500 test samples randomly sampled (use `sklearn.cross_validation.ShuffleSplit`).\n",
      "- Try with `SVC(C=1, gamma=0.01)`\n",
      "- Plot distribution the test error using an histogram with 50 bins.\n",
      "- Try to increas the training size\n",
      "- Retry with `SVC(C=10, gamma=0.005)`, then `SVC(C=10, gamma=0.001)` with 500 samples.\n",
      "\n",
      "- Optional: use a smoothed kernel density estimation `scipy.stats.kde.gaussian_kde` instead of an histogram to visualize the test error distribution.\n",
      "\n",
      "Hints, type:\n",
      "\n",
      "    from sklearn.cross_validation import ShuffleSplit\n",
      "    ShuffleSplit?  # to read the docstring of the shuffle split\n",
      "    pl.hist?  # to read the docstring of the histogram plot\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = ShuffleSplit(n_samples, n_iter=50, train_size=500, test_size=500,\n",
      "    random_state=0)\n",
      "%time scores = cross_val_score(SVC(C=10, gamma=0.005), X, y, cv=cv)\n",
      "print(mean_score(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.48 s, sys: 12.6 ms, total: 4.49 s\n",
        "Wall time: 4.5 s\n",
        "Mean score: 0.905 [0.897 - 0.914]\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.kde import gaussian_kde\n",
      "#_ = pl.hist(scores, range=(0, 1), bins=50)\n",
      "x = np.linspace(0, 1, 1000)\n",
      "pl.plot(x, gaussian_kde(scores).evaluate(x))\n",
      "_ = pl.title(\"Cross Validated test scores distribution\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAHLCAYAAAADXnZlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4CaCFAAAgJsIUgAAAG76/0/2kMElwiKFAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10ccb5e10>"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plotting Learning Curves for Bias-Variance analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_sizes = np.logspace(2, 3, 3).astype(np.int)\n",
      "train_sizes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Interpreting Learning Curves"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- If the **training set error is high** (e.g. more than 10% misclassification) at the end of the learning curve, the model suffers from **high bias** and is said to **under-fit** the training set.\n",
      "\n",
      "- If the **testing set error is significantly larger than the training set error**, the model suffers from **high variance** and is said to **over-fit** the training set.\n",
      "\n",
      "- Another possible source of high training or testing error is label noise: the data is too noisy and there is nothing few signal learn from it."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "What to do against overfitting?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Try to get rid of noisy features using feature selection methods\n",
      "- Try to tune parameters to add more regularization:\n",
      "    - Smaller values of `C` for SVM\n",
      "    - Larger values of `alpha` for penalized linear models\n",
      "    - Restrict to shallower trees (decision stumps) and lower numbers of samples per leafs for tree-based models\n",
      "- Try simpler models such as penalized linear models (e.g. Linear SVM, Logistic Regression, Naive Bayes)\n",
      "- Try the bagging ensemble strategies: average the predictions of independently trained models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "What to do against underfitting?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Give more freedom to the model by relaxing some parameters that act as regularizers:\n",
      "    - Larger values of `C` for SVM\n",
      "    - Smaller values of `alpha` for penalized linear models\n",
      "    - Allow deeper trees and lower numbers of samples per leafs for tree-based models\n",
      "- Try more complex / expressive models:\n",
      "    - Non linear kernel SVMs,\n",
      "    - Ensemble of Decision Trees...)\n",
      "- Construct new features (e.g. bi-gram frequencies for text classifications or K-Means features, feature cross-products or non-linear kernel approximations)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "TODO: provide the parameters for an underfitting (model, dataset) pair then ask student to plot the learning curves and propose and test solutions \n",
      "\n",
      "TODO: provide the parameters for an overfitting (model, dataset) pair then ask the studen to plot learning curves and propose and test solutions "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parallel Computation of Learning Curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "rc = Client()\n",
      "lv = rc.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import namedtuple\n",
      "from collections import defaultdict\n",
      "\n",
      "\n",
      "def compute_evaluation(model, X_train, y_train, X_test, y_test,\n",
      "                       cv_index, params=None):\n",
      "    \"\"\"Function executed on a worker to evaluate a model on a given CV fold\"\"\"\n",
      "    # All module imports should be executed in the worker namespace\n",
      "    from time import time\n",
      "    \n",
      "    # Fit model and measure training time\n",
      "    t0 = time()\n",
      "    model.fit(X_train, y_train)\n",
      "    train_time = time() - t0\n",
      "    \n",
      "    # Compute score on training set\n",
      "    train_score = model.score(X_train, y_train)\n",
      "    \n",
      "    # Compute score on test set\n",
      "    test_score = model.score(X_test, y_test)\n",
      "\n",
      "    # Wrap evaluation results in a simple tuple datastructure\n",
      "    return (test_score, train_score, train_time,\n",
      "            X_train.shape[0], cv_index, params)\n",
      "\n",
      "\n",
      "# Named tuple to collect evaluation results\n",
      "Evaluation = namedtuple('Evaluation', (\n",
      "    'test_score',\n",
      "    'train_score',\n",
      "    'train_time',\n",
      "    'train_size',\n",
      "    'cv_index',\n",
      "    'parameters'))\n",
      "\n",
      "\n",
      "class LearningCurves(object):\n",
      "    \"\"\"Handle async, distributed evaluation of a model learning curves\"\"\"\n",
      "    \n",
      "    def __init__(self, load_balancer):\n",
      "        self._scheduled_tasks = []\n",
      "        self._load_balancer = load_balancer\n",
      "\n",
      "    def evaluate(self, model, X, y, train_sizes=np.linspace(0.1, 0.8, 8),\n",
      "        test_size=0.2, n_iter=5):\n",
      "        \"\"\"Schedule evaluation work in parallel and aggregate results for plotting\"\"\"\n",
      "        \n",
      "        n_samples, n_features = X.shape\n",
      "        self.n_samples = n_samples\n",
      "        \n",
      "        # Abort any other previously scheduled tasks\n",
      "        for task in self._scheduled_tasks:\n",
      "            if not task.ready():\n",
      "                task.abort()\n",
      "\n",
      "        # Schedule a new batch of evalutation tasks\n",
      "        self._scheduled_tasks = []\n",
      "        for train_size in train_sizes:\n",
      "            cv = ShuffleSplit(n_samples, n_iter=n_iter, \n",
      "                              train_size=train_size,\n",
      "                              test_size=test_size)\n",
      "            for cv_index, (train, test) in enumerate(cv):\n",
      "                task = self._load_balancer.apply_async(\n",
      "                    compute_evaluation,\n",
      "                    clf, X[train], y[train], X[test], y[test],\n",
      "                    cv_index)\n",
      "                \n",
      "                self._scheduled_tasks.append(task)\n",
      "        \n",
      "        # Make it possible to chain method calls\n",
      "        return self\n",
      "                \n",
      "    def wait(self):\n",
      "        \"\"\"Wait for completion\"\"\"\n",
      "        for task in self._scheduled_tasks:\n",
      "            task.wait()\n",
      "        \n",
      "        # Make it possible to chain method calls\n",
      "        return self\n",
      "    \n",
      "    def update_summary(self):\n",
      "        \"\"\"Compute summary statistics for all finished tasks\"\"\"\n",
      "        evaluations = [Evaluation(*t.get())\n",
      "                       for t in self._scheduled_tasks if t.ready()]\n",
      "        grouped_evaluations = defaultdict(list)\n",
      "        for ev in evaluations:\n",
      "            # Group evaluations by effective training sizes\n",
      "            grouped_evaluations[ev.train_size].append(ev)\n",
      "        \n",
      "        self.train_sizes = []\n",
      "        self.train_scores, self.train_scores_ci_width = [], []\n",
      "        self.test_scores, self.test_scores_ci_width = [], []\n",
      "        self.train_times, self.train_times_ci_width = [], []\n",
      "    \n",
      "        for size, group in sorted(grouped_evaluations.items()):\n",
      "            self.train_sizes.append(size)\n",
      "    \n",
      "            # Aggregate training scores data\n",
      "            train_mean, train_ci_width = mean_with_ci(\n",
      "                [ev.train_score for ev in group])\n",
      "            self.train_scores.append(train_mean)\n",
      "            self.train_scores_ci_width.append(train_ci_width)\n",
      "    \n",
      "            # Aggregate testing scores data\n",
      "            test_mean, test_ci_width = mean_with_ci(\n",
      "                [ev.test_score for ev in group])\n",
      "            self.test_scores.append(test_mean)\n",
      "            self.test_scores_ci_width.append(test_ci_width)\n",
      "            \n",
      "            # Aggregate training times data\n",
      "            train_time, train_time_ci_width = mean_with_ci(\n",
      "                [ev.train_time for ev in group])\n",
      "            self.train_times.append(train_time)\n",
      "            self.train_times_ci_width.append(train_time_ci_width)\n",
      "            \n",
      "    def __repr__(self):\n",
      "        \"\"\"Display current evaluation statistics\"\"\"\n",
      "        self.update_summary()\n",
      "        if not self.test_scores:\n",
      "            return \"Missing evaluation statistics\"\n",
      "        n_total = len(self._scheduled_tasks)\n",
      "        n_done = len([t for t in self._scheduled_tasks if t.ready()])\n",
      "        last_test = self.test_scores[-1]\n",
      "        last_train = self.train_scores[-1]\n",
      "        last_duration = self.train_times[-1]\n",
      "        overfitting = np.max(last_train - last_test, 0)\n",
      "        underfitting = np.max(1 - last_train, 0)\n",
      "        return (\n",
      "                \"tasks: {n_done}/{n_total}\\n\"\n",
      "                \"last test score: {last_test:.3f}\\n\"\n",
      "                \"last train score: {last_train:.3f}\\n\"\n",
      "                \"last train time: {last_duration:.3f}s\\n\"\n",
      "                \"overfitting: {overfitting:.3f}\\n\"\n",
      "                \"underfitting: {underfitting:.3f}\\n\"\n",
      "        ).format(**locals())\n",
      "\n",
      "\n",
      "def plot_learning_curves(lc):\n",
      "    \"\"\"Interative plot of a learning curve\"\"\"\n",
      "    lc.update_summary()  # ensure that stats are up to date\n",
      "    pl.figure()\n",
      "    if hasattr(lc, 'train_times'):\n",
      "        pl.subplot(211)\n",
      "    pl.errorbar(lc.train_sizes,\n",
      "                lc.train_scores,\n",
      "                lc.train_scores_ci_width,\n",
      "                label='train')\n",
      "    pl.errorbar(lc.train_sizes,\n",
      "                lc.test_scores,\n",
      "                lc.test_scores_ci_width,\n",
      "                label='test')\n",
      "    pl.ylabel('Score')\n",
      "    pl.xlim(0, lc.n_samples)\n",
      "    pl.ylim((None, 1.01))  # The best possible score is 1.0\n",
      "    pl.xticks(())\n",
      "    pl.legend(loc='best')\n",
      "    pl.title('Learning curves for SVM model on digits data')\n",
      "    \n",
      "    if hasattr(lc, 'train_times'):\n",
      "        pl.subplot(212)\n",
      "        pl.errorbar(lc.train_sizes,\n",
      "                    lc.train_times,\n",
      "                    lc.train_times_ci_width)\n",
      "        pl.xlim(0, lc.n_samples)\n",
      "        pl.ylabel('Training time (s)')\n",
      "        pl.xlabel('# training samples')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SVC(kernel='rbf', C=1, gamma=0.001)\n",
      "lc = LearningCurves(lv)\n",
      "lc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lc.evaluate(clf, X, y, n_iter=50)\n",
      "lc"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lv.abort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_learning_curves(lc)\n",
      "lc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "plot_learning_curves(lc.wait())\n",
      "lc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model Selection with Grid Search"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO: explain"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#help(GridSearchCV)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "params = {\n",
      "    'C': np.logspace(-1, 2, 4),\n",
      "    'gamma': np.logspace(-4, 0, 5)[::-1],\n",
      "}\n",
      "pprint(params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "%time gs = GridSearchCV(SVC(), params, n_jobs=-1).fit(X_train[:500], y_train[:500])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_, gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's define a couple of helper function to help us introspect the details of the grid search outcome:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def display_scores(params, scores):\n",
      "    \"\"\"Format the mean score +/- std error for params\"\"\"\n",
      "    stderr = np.std(scores) / np.sqrt(scores.shape[0])\n",
      "    params = \", \".join(\"{0}={1}\".format(k, v)\n",
      "                      for k, v in params.items())\n",
      "    return \"{0}:\\t{1:.3f} (+/-{2:.3f})\".format(\n",
      "        params, np.mean(scores), stderr)\n",
      "\n",
      "def display_grid_scores(grid_scores, sort=True):\n",
      "    \"\"\"Helper function to format a report on a grid of scores\"\"\"\n",
      "    if sort:\n",
      "        grid_scores = sorted(grid_scores,\n",
      "             key=lambda x: x[1], reverse=True)\n",
      "        \n",
      "    for params, _, scores in grid_scores:\n",
      "        print(display_scores(params, scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display_grid_scores(gs.grid_scores_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default, the `GridSearchCV` class refits a final model on the complete training set with the best parameters found by during the grid search. Evaluating this final model on the real test set will often yield a slightly better score because of the larger training set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "1. Find a set of parameters for an `sklearn.ensemble.ExtraTreesClassifier` on the same dataset to reach at least 92% accuracy on the sample dataset (500 training samples) with a maximum of 10 sub-estimators (decision trees in this case): `n_estimators=10`\n",
      "2. In particular you can grid search good values for `min_samples_split` and optionally `criterion`\n",
      "3. Analysis: retry the experiment with `n_estimators=50` and then `n_estimator=100`.\n",
      "    - What is the impact of large values of `n_estimators` on the optimal value of `min_samples_split`?\n",
      "    - How would you explain this phenomenom in terms of Bias / Variance trade-off?\n",
      "\n",
      "Hints:\n",
      "\n",
      "- ExtraTrees are randomized models, be sure to run the grid search several times to check the stability of the outcome.\n",
      "- If the outcome of the grid search is too instable (overlapping std errors), increase the number of CV folds with `cv` constructor parameter. The default value is `cv=3`. `cv=5` or `cv=10` often yield more stable results (but at the price of longer evaluation times).\n",
      "- Start with a small grid, e.g. 3 values for `min_samples_split` only to avoid having to wait for too long at first.\n",
      "\n",
      "Type:\n",
      "\n",
      "    from sklearn.ensemble.ExtraTreesClassifier\n",
      "    ExtraTreesClassifier?  # to read the docstring and know the list of important parameters\n",
      "    print(ExtraTreesClassifier())  # to show the list of default values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "print(ExtraTreesClassifier())\n",
      "#ExtraTreesClassifier?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = {\n",
      "    #'criterion': ['gini', 'entropy'],\n",
      "    'n_estimators': [1, 10, 100, 200],\n",
      "}\n",
      "trees = RandomForestClassifier(n_estimators=10)\n",
      "gs_trees = GridSearchCV(trees, params, n_jobs=-1, cv=5)\n",
      "\n",
      "%time gs_trees.fit(X_train, y_train)\n",
      "display_grid_scores(gs_trees.grid_scores_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Distributed Model Selection with Grid Search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import IterGrid\n",
      "\n",
      "params = {\n",
      "    'C': np.logspace(-1, 2, 4),\n",
      "    'gamma': np.logspace(-4, 0, 5)[::-1],\n",
      "}\n",
      "list(IterGrid(params))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class DistributedGridSearch(object):\n",
      "    \"\"\"IPython.parallel implementation of grid search\"\"\"\n",
      "\n",
      "    def __init__(self, load_balancer):\n",
      "        self._scheduled_tasks = []\n",
      "        self._load_balancer = load_balancer\n",
      "\n",
      "    def evaluate(self, model, params_grid X, y, n_iter=5):\n",
      "        \"\"\"Schedule evaluation work in parallel and aggregate results for plotting\"\"\"\n",
      "        \n",
      "        # Abort any other previously scheduled tasks\n",
      "        for task in self._scheduled_tasks:\n",
      "            if not task.ready():\n",
      "                task.abort()\n",
      "\n",
      "        # Schedule a new batch of evalutation tasks\n",
      "        self._scheduled_tasks = []\n",
      "        for params in IterGrid(params_grid):\n",
      "            cv = ShuffleSplit(n_samples, n_iter=n_iter, \n",
      "                              train_size=train_size,\n",
      "                              test_size=test_size)\n",
      "            for train, test in cv:\n",
      "                task = self._load_balancer.apply_async(\n",
      "                    compute_evaluation,\n",
      "                    clf, X[train], y[train], X[test], y[test], params=params)\n",
      "                self._scheduled_tasks.append(task)\n",
      "                \n",
      "        # Make it possible to chain method calls\n",
      "        return self\n",
      "                \n",
      "    def wait(self):\n",
      "        \"\"\"Wait for completion\"\"\"\n",
      "        for task in self._scheduled_tasks:\n",
      "            task.wait()\n",
      "        \n",
      "        # Make it possible to chain method calls\n",
      "        return self\n",
      "    \n",
      "    def update_summary(self):\n",
      "        \"\"\"Compute summary statistics for all finished tasks\"\"\"\n",
      "        evaluations = [Evaluation(*t.get())\n",
      "                       for t in self._scheduled_tasks if t.ready()]\n",
      "        grouped_evaluations = defaultdict(list)\n",
      "        for ev in evaluations:\n",
      "            # Group evaluations by effective training sizes\n",
      "            grouped_evaluations[ev.train_size].append(ev)\n",
      "        \n",
      "        self.train_sizes = []\n",
      "        self.train_scores, self.train_scores_ci_width = [], []\n",
      "        self.test_scores, self.test_scores_ci_width = [], []\n",
      "        self.train_times, self.train_times_ci_width = [], []\n",
      "    \n",
      "        for size, group in sorted(grouped_evaluations.items()):\n",
      "            self.train_sizes.append(size)\n",
      "    \n",
      "            # Aggregate training scores data\n",
      "            train_mean, train_ci_width = mean_with_ci(\n",
      "                [ev.train_score for ev in group])\n",
      "            self.train_scores.append(train_mean)\n",
      "            self.train_scores_ci_width.append(train_ci_width)\n",
      "    \n",
      "            # Aggregate testing scores data\n",
      "            test_mean, test_ci_width = mean_with_ci(\n",
      "                [ev.test_score for ev in group])\n",
      "            self.test_scores.append(test_mean)\n",
      "            self.test_scores_ci_width.append(test_ci_width)\n",
      "            \n",
      "            # Aggregate training times data\n",
      "            train_time, train_time_ci_width = mean_with_ci(\n",
      "                [ev.train_time for ev in group])\n",
      "            self.train_times.append(train_time)\n",
      "            self.train_times_ci_width.append(train_time_ci_width)\n",
      "            \n",
      "    def __repr__(self):\n",
      "        \"\"\"Display current evaluation statistics\"\"\"\n",
      "        self.update_summary()\n",
      "        if not self.test_scores:\n",
      "            return \"Missing evaluation statistics\"\n",
      "        n_total = len(self._scheduled_tasks)\n",
      "        n_done = len([t for t in self._scheduled_tasks if t.ready()])\n",
      "        last_test = self.test_scores[-1]\n",
      "        last_train = self.train_scores[-1]\n",
      "        last_duration = self.train_times[-1]\n",
      "        overfitting = np.max(last_train - last_test, 0)\n",
      "        underfitting = np.max(1 - last_train, 0)\n",
      "        return (\n",
      "                \"tasks: {n_done}/{n_total}\\n\"\n",
      "                \"last test score: {last_test:.3f}\\n\"\n",
      "                \"last train score: {last_train:.3f}\\n\"\n",
      "                \"last train time: {last_duration:.3f}s\\n\"\n",
      "                \"overfitting: {overfitting:.3f}\\n\"\n",
      "                \"underfitting: {underfitting:.3f}\\n\"\n",
      "        ).format(**locals())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise:** learning curves and grid search\n",
      "\n",
      "- combine the previous examples to compute the learning curves data and grid search in parallel\n",
      "- plot the learning curves of the top 3 models (ranked by high test scores and small durations in case of tie)\n",
      "- are the best models overfitting overfitting or underfitting?\n",
      "- would the models benefit from a larger labeled dataset?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Final Model Assessment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Risk of not taking into account the overfitting of the grid search procedure it-self\n",
      "- Development / Evaluation sets split\n",
      "- Development used for Grid Search and training of the model with optimal parameter set\n",
      "- Hold out evaluation set used **only** for estimating the predictive performance of the resulting model\n",
      "- Recommended to use temporal split for the Development / Evaluation split for data points collected over time (for instance  2008-2011 for development, 2012 for evaluation)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO: use matplotlib to generate train / validation / test splits where train +  validation is the development set and test is the evaluation set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}