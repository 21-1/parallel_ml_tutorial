{
 "metadata": {
  "name": "04 - Large Scale Text Classification for Sentiment Analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "\n",
      "# Some nice default configuration for plots\n",
      "pl.rcParams['figure.figsize'] = 10, 7.5\n",
      "pl.rcParams['axes.grid'] = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Large Scale Text Classification for Sentiment Analysis"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Outline of the Session"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Limitation of the Vocabulary based vectorizer\n",
      "- The Hashing Trick\n",
      "- Parallel Text Feature Extraction and Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scalability Issues"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Memory usage of text feature extraction\n",
      "- Parallelization issues for text feature extraction\n",
      "- Out-of-core / online learning\n",
      "- Sharding / distributing computation on a cluster"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The Sentiment 140 Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "sentiment140_folder = os.path.join('..', 'datasets', 'sentiment140')\n",
      "training_csv_file = os.path.join(sentiment140_folder, 'training.1600000.processed.noemoticon.csv')\n",
      "testing_csv_file = os.path.join(sentiment140_folder, 'testdata.manual.2009.06.14.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls -lh ../datasets/sentiment140/training.1600000.processed.noemoticon.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's parse the CSV files and load everything in memory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "import csv\n",
      "fieldnames = ('polarity', 'id', 'date', 'query', 'author', 'text')\n",
      "\n",
      "with open(training_csv_file, 'rb') as f:\n",
      "    train_dicts = list(csv.DictReader(f, fieldnames=fieldnames, delimiter=',', quotechar='\"'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(train_dicts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_dicts[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's extract the positive and negative texts and ignore the neutral for now:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "train_text_positive = [d['text'] for d in train_dicts if d['polarity'] == '4']\n",
      "train_text_negative = [d['text'] for d in train_dicts if d['polarity'] == '0']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(train_text_positive), len(train_text_negative)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "with open(testing_csv_file, 'rb') as f:\n",
      "    test_dicts = list(csv.DictReader(f, fieldnames=fieldnames, delimiter=',', quotechar='\"'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(test_dicts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_dicts[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_dicts[-3:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The Hashing Trick"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Out-of-Core learning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parallizing Text Feature Extraction and Classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}