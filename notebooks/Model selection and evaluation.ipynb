{
 "metadata": {
  "name": "Model selection and evaluation"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model selection and evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Outline of the session:\n",
      "\n",
      "- Model evaluation without overfitting with Cross-Validation\n",
      "- Hyper parameter tuning and model selection with Grid Search\n",
      "- Error analysis with learning curves and the Bias-Variance trade-off"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "pl.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      },
      {
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x1042ea750>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overfitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overfitting is the problem of learning the training data by heart and being unable to generalize by making correct predictions on new data.\n",
      "\n",
      "Let's load a simple dataset of 8x8 gray level images of handwritten digits:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()\n",
      "X, y = digits.data, digits.target\n",
      "print(\"data shape: %r, target shape: %r\" % (X.shape, y.shape))\n",
      "print(\"classes: %r\" % list(np.unique(y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data shape: (1797, 64), target shape: (1797,)\n",
        "classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples, n_features = X.shape\n",
      "print(\"n_samples=%d\" % n_samples)\n",
      "print(\"n_features=%d\" % n_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "n_samples=1797\n",
        "n_features=64\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl.figure()\n",
      "pl.imshow(X[0].reshape((8, 8)), interpolation='nearest')\n",
      "print(\"Target class: %d\" % y[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Target class: 0\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD5CAYAAAAURMgdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw7ZNUdMxJBoAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10387dd50>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "SVC().fit(X, y).score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Did we really learn a perfect model that can recognize the correct digit class 100% of the time? **Without new data it's impossible to tell.**\n",
      "\n",
      "Let's start again and split the dataset into two random, non overlapping subsets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
      "print(\"train data shape: %r, train target shape: %r\" % (X_train.shape, y_train.shape))\n",
      "print(\"test data shape: %r, test target shape: %r\" % (X_test.shape, y_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train data shape: (1347, 64), train target shape: (1347,)\n",
        "test data shape: (450, 64), test target shape: (450,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's retrain a new model on the first subset call the **training set**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC(kernel='rbf').fit(X_train, y_train)\n",
      "train_score = svc.score(X_train, y_train) \n",
      "train_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now compute the performance of the model on new, held out data from the **test set**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_score = svc.score(X_test, y_test)\n",
      "test_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "0.37555555555555553"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This score is clearly not as good as expected! The model cannot generalize so well to new, unseen data.\n",
      "\n",
      "- Whenever the **test** data score is **not as good as** the **train** score the model is **overfitting**\n",
      "\n",
      "- Whenever the **train score is not close to 100%** accuracy the model is **underfitting**\n",
      "\n",
      "Ideally **we want to neither overfit nor underfit**: `test_score ~= train_score ~= 1.0`. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- TODO: n_jobs cross validation\n",
      "- TODO: std of test error"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import ShuffleSplit\n",
      "\n",
      "cv = ShuffleSplit(n_samples, n_iter=3, test_size=0.1)\n",
      "for train, test in cv:\n",
      "    print(\"train indices: {0}...\".format(train[:10]))\n",
      "    print(\"test indices: {0}...\".format(test[:10]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train indices: [   4  946  587 1642    5  860 1661   70  219  604]...\n",
        "test indices: [1490  782 1426 1208  359 1699 1060 1058  816 1454]...\n",
        "train indices: [ 463 1113  409  135  227  918  829 1776 1514  292]...\n",
        "test indices: [1464 1766 1746  339  586  139  136  591  193  291]...\n",
        "train indices: [1403  175  976 1362  735  800 1542 1252  593 1399]...\n",
        "test indices: [ 711 1603  398  652 1456 1347 1340 1137 1031 1512]...\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "# TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mean_with_ci(scores, min_=0, max_=1):\n",
      "    \"\"\"Compute the mean score and standard 95% Confidence Interval\n",
      "\n",
      "    Assume that the distribution of the scores is normal which\n",
      "    is probably not true when the mean is close to an upper or\n",
      "    lower bound.\n",
      "\n",
      "    For better CI evaluation, use scikits.bootstrap.\n",
      "    \"\"\"\n",
      "    scores = np.asarray(scores).ravel()\n",
      "    m, s = np.mean(scores), np.std(scores)\n",
      "    std_error = s / np.sqrt(scores.shape[0])\n",
      "    ci_min = max(m - 1.96 * std_error, min_)\n",
      "    ci_max = min(m + 1.96 * std_error, max_)\n",
      "    return m, ci_min, ci_max\n",
      "\n",
      "def mean_score(scores, min_=0, max_=1):\n",
      "    \"\"\"Print the mean score and standard 95% Confidence Interval\"\"\"\n",
      "    m, ci_min, ci_max = mean_with_ci(scores, min_, max_)\n",
      "    return (\"Mean score: {0:.3f} [{1:.3f} - {2:.3f}]\").format(\n",
      "        m, ci_min, ci_max)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise:** \n",
      "\n",
      "- Perform 50 iterations of cross validation with randomly sampled folds of 500 training samples and 500 test samples randomly sampled (use `sklearn.cross_validation.ShuffleSplit`).\n",
      "- Try with `SVC(C=1, gamma=0.01)`\n",
      "- Plot the histogram of the test error 30 bins.\n",
      "- Try to increas the training size\n",
      "- Retry with `SVC(C=10, gamma=0.005)`, then `SVC(C=10, gamma=0.001)` with 500 samples.\n",
      "\n",
      "Hints, type:\n",
      "\n",
      "    from sklearn.cross_validation import ShuffleSplit\n",
      "    ShuffleSplit?  # to read the docstring of the shuffle split\n",
      "    pl.hist?  # to read the docstring of the histogram plot\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = ShuffleSplit(n_samples, n_iter=50, train_size=500, test_size=500)\n",
      "%time scores = cross_val_score(SVC(C=10, gamma=0.005), X, y, cv=cv)\n",
      "_ = pl.hist(scores, range=(0, 1), bins=30)\n",
      "print(mean_score(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.36 s, sys: 0.01 s, total: 4.37 s\n",
        "Wall time: 4.37 s\n",
        "Mean score: 0.902 [0.893 - 0.910]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD9CAYAAABOd5eOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x105b4e1d0>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plotting Learning Curves for Bias-Variance analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_sizes = np.logspace(2, 3, 3).astype(np.int)\n",
      "train_sizes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "array([ 100,  316, 1000])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parallel Computation of Learning Curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "rc = Client()\n",
      "lv = rc.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import namedtuple\n",
      "from collections import defaultdict\n",
      "\n",
      "# Named tuple to collect evaluation results\n",
      "Evaluation = namedtuple('Evaluation', (\n",
      "    'test_score',\n",
      "    'train_score',\n",
      "    'train_time',\n",
      "    'train_size'))\n",
      "\n",
      "\n",
      "def evaluate(model, X_train, y_train, X_test, y_test):\n",
      "    \"\"\"Function executed on a worker to evaluate a model on a given CV fold\"\"\"\n",
      "    from time import time\n",
      "    # Fit model and measure training time\n",
      "    t0 = time()\n",
      "    model.fit(X_train, y_train)\n",
      "    train_time = time() - t0\n",
      "    \n",
      "    # Compute score on training set\n",
      "    train_score = model.score(X_train, y_train)\n",
      "    \n",
      "    # Compute score on test set\n",
      "    test_score = model.score(X_test, y_test)\n",
      "\n",
      "    # Wrap evaluation results in a tuple datastructure\n",
      "    return (test_score, train_score, train_time, X_train.shape[0])\n",
      "\n",
      "\n",
      "def learning_curves(model, X, y, train_sizes=[0.2, 0.4, 0.6, 0.8],\n",
      "    test_size=0.2, n_iter=5):\n",
      "    \"\"\"Schedule evaluation work in parallel and aggregate results for plotting\"\"\"\n",
      "    tasks = []\n",
      "    for train_size in train_sizes:\n",
      "        cv = ShuffleSplit(n_samples, n_iter=n_iter, \n",
      "                          train_size=train_size,\n",
      "                          test_size=test_size)\n",
      "        for train, test in cv:\n",
      "            tasks.append(lv.apply_async(evaluate, clf, X[train], y[train], X[test], y[test]))\n",
      "            \n",
      "    evaluations = [Evaluation(*t.get()) for t in tasks]\n",
      "    grouped_evaluations = defaultdict(list)\n",
      "    for ev in evaluations:\n",
      "        # Group evaluations by effective training sizes\n",
      "        grouped_evaluations[ev.train_size].append(ev)\n",
      "    \n",
      "    effective_train_sizes = []\n",
      "    train_scores_min, train_scores, train_scores_max = [], [], []\n",
      "    test_scores_min, test_scores, test_scores_max = [], [], []\n",
      "    for size, group in sorted(grouped_evaluations.items()):\n",
      "        effective_train_sizes.append(size)\n",
      "\n",
      "        # Aggregate training scores data\n",
      "        train_mean, train_min, train_max = mean_with_ci(\n",
      "            [ev.train_score for ev in group])\n",
      "        train_scores.append(train_mean)\n",
      "        train_scores_min.append(train_min)\n",
      "        train_scores_max.append(train_max)\n",
      "\n",
      "        # Aggregate testing scores data\n",
      "        test_mean, test_min, test_max = mean_with_ci(\n",
      "            [ev.test_score for ev in group])\n",
      "        test_scores.append(test_mean)\n",
      "        test_scores_min.append(test_min)\n",
      "        test_scores_max.append(test_max)\n",
      "    \n",
      "    return (effective_train_sizes,\n",
      "            train_scores, train_scores_min, train_scores_max,\n",
      "            test_scores, test_scores_min, test_scores_max)\n",
      "    \n",
      "    \n",
      "clf = SVC(kernel='linear', C=0.0001, gamma=0.0001)\n",
      "evaluations = learning_curves(clf, X, y)\n",
      "evaluations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "([359, 718, 1078, 1437],\n",
        " [0.94038997214484676,\n",
        "  0.95292479108635086,\n",
        "  0.96141001855287556,\n",
        "  0.96631871955462767],\n",
        " [0.93560540963694649,\n",
        "  0.9457479473245004,\n",
        "  0.95870832028072916,\n",
        "  0.96494932193291005],\n",
        " [0.94517453465274703,\n",
        "  0.96010163484820132,\n",
        "  0.96411171682502195,\n",
        "  0.96768811717634529],\n",
        " [0.89888888888888885,\n",
        "  0.94888888888888889,\n",
        "  0.96055555555555538,\n",
        "  0.95944444444444454],\n",
        " [0.87702417352879836,\n",
        "  0.94493275909286811,\n",
        "  0.95220582945669885,\n",
        "  0.95000182501293107],\n",
        " [0.92075360424897934,\n",
        "  0.95284501868490967,\n",
        "  0.96890528165441192,\n",
        "  0.96888706387595802])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model Selection with Grid Search"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO: explain"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#help(GridSearchCV)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "params = {\n",
      "    'C': np.logspace(-1, 2, 4),\n",
      "    'gamma': np.logspace(-4, 0, 5)[::-1],\n",
      "}\n",
      "pprint(params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'C': array([   0.1,    1. ,   10. ,  100. ]),\n",
        " 'gamma': array([  1.00000000e+00,   1.00000000e-01,   1.00000000e-02,\n",
        "         1.00000000e-03,   1.00000000e-04])}\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "%time gs = GridSearchCV(SVC(), params, n_jobs=-1).fit(X_train[:500], y_train[:500])\n",
      "gs.best_params_, gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 0.09 s, sys: 0.05 s, total: 0.14 s\n",
        "Wall time: 0.97 s\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "({'C': 1.0, 'gamma': 0.001}, 0.96202775172546473)"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "0.98444444444444446"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- find a set of parameters for an `sklearn.ensemble.ExtraTreesClassifier` on the same dataset to reach at least 94% accuracy on the sample dataset (500 training samples) with a maximum of 100 sub-estimtors (decision trees in this case): `n_estimators=100`\n",
      "- in particular you can grid search good values for `max_depth`, `min_samples_leaf` and optionally `criterion`\n",
      "\n",
      "Hints:\n",
      "\n",
      "Type:\n",
      "\n",
      "    from sklearn.ensemble.ExtraTreesClassifier\n",
      "    ExtraTreesClassifier?  # to read the docstring and know the list of important parameters\n",
      "    print(ExtraTreesClassifier())  # to know the list of default values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "print(ExtraTreesClassifier())\n",
      "# ExtraTreesClassifier?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ExtraTreesClassifier(bootstrap=False, compute_importances=False,\n",
        "           criterion=gini, max_depth=None, max_features=auto,\n",
        "           min_density=0.1, min_samples_leaf=1, min_samples_split=1,\n",
        "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
        "           verbose=0)\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = {\n",
      "    #'criterion': ['gini', 'entropy'],\n",
      "    'max_depth': [10, 20, None],\n",
      "    'min_samples_leaf': [1, 2, 5],\n",
      "}\n",
      "%time gs = GridSearchCV(ExtraTreesClassifier(n_estimators=100), params, n_jobs=-1).fit(X_train[:500], y_train[:500])\n",
      "gs.best_params_, gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.14 s, sys: 0.04 s, total: 1.18 s\n",
        "Wall time: 9.33 s\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "({'max_depth': 20, 'min_samples_leaf': 1}, 0.94401558329124868)"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 128,
       "text": [
        "0.97111111111111115"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Distributed Model Selection with Grid Search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import IterGrid\n",
      "list(IterGrid(params))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "[{'max_depth': 10, 'min_samples_leaf': 1},\n",
        " {'max_depth': 10, 'min_samples_leaf': 2},\n",
        " {'max_depth': 10, 'min_samples_leaf': 5},\n",
        " {'max_depth': 20, 'min_samples_leaf': 1},\n",
        " {'max_depth': 20, 'min_samples_leaf': 2},\n",
        " {'max_depth': 20, 'min_samples_leaf': 5},\n",
        " {'max_depth': None, 'min_samples_leaf': 1},\n",
        " {'max_depth': None, 'min_samples_leaf': 2},\n",
        " {'max_depth': None, 'min_samples_leaf': 5}]"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise:** learning curves and grid search\n",
      "\n",
      "- combine the previous examples to compute the learning curves data and grid search in parallel\n",
      "- plot the learning curves of the top 3 models (ranked by high test scores and small durations in case of tie)\n",
      "- are the best models overfitting overfitting or underfitting?\n",
      "- would the models benefit from a larger labeled dataset?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}