{
 "metadata": {
  "name": "Model selection and evaluation"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model selection and evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Outline of the session:\n",
      "\n",
      "- Model evaluation without overfitting with Cross-Validation\n",
      "- Hyper parameter tuning and model selection with Grid Search\n",
      "- Error analysis with learning curves and the Bias-Variance trade-off"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "pl.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      },
      {
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x10f5e1750>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overfitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overfitting is the problem of learning the training data by heart and being unable to generalize by making correct prediction on new data.\n",
      "\n",
      "Let's load a simple dataset of 8x8 gray level images of handwritten digits:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()\n",
      "X, y = digits.data, digits.target\n",
      "print(\"data shape: %r, target shape: %r\" % (X.shape, y.shape))\n",
      "print(\"classes: %r\" % list(np.unique(y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data shape: (1797, 64), target shape: (1797,)\n",
        "classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples, n_features = X.shape\n",
      "print(\"n_samples=%d\" % n_samples)\n",
      "print(\"n_features=%d\" % n_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "n_samples=1797\n",
        "n_features=64\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl.figure()\n",
      "pl.imshow(X[0].reshape((8, 8)), interpolation='nearest')\n",
      "print(\"Target class: %d\" % y[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Target class: 0\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD5CAYAAAAURMgdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw7ZNUdMxJBoAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10eb74bd0>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "SVC().fit(X, y).score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Did we really learn a perfect model that can recognize the correct digit class 100% of the time? **Without new data it's impossible to tell.**\n",
      "\n",
      "Let's start again and split the dataset into two random, non overlapping subsets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
      "print(\"train data shape: %r, train target shape: %r\" % (X_train.shape, y_train.shape))\n",
      "print(\"test data shape: %r, test target shape: %r\" % (X_test.shape, y_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train data shape: (1347, 64), train target shape: (1347,)\n",
        "test data shape: (450, 64), test target shape: (450,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's retrain a new model on the first subset call the **training set**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC(kernel='rbf').fit(X_train, y_train)\n",
      "train_score = svc.score(X_train, y_train) \n",
      "train_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now compute the performance of the model on new, held out data from the **test set**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_score = svc.score(X_test, y_test)\n",
      "test_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "0.38444444444444442"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This score is clearly not as good as expected! The model cannot generalize so well to new, unseen data.\n",
      "\n",
      "- Whenever the **test** data score is **not as good as** the **train** score the model is **overfitting**\n",
      "\n",
      "- Whenever the **train score is not close to 100%** accuracy the model is **underfitting**\n",
      "\n",
      "Ideally **we want to neither overfit nor underfit**: `test_score ~= train_score ~= 1.0`. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- TODO: n_jobs cross validation\n",
      "- TODO: std of test error"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import ShuffleSplit\n",
      "\n",
      "cv = ShuffleSplit(n_samples, n_iter=3, test_size=0.1)\n",
      "for train, test in cv:\n",
      "    print(\"train indices: {0}...\".format(train[:10]))\n",
      "    print(\"test indices: {0}...\".format(test[:10]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train indices: [ 329  700  932 1623 1218  840  436 1210 1785 1202]...\n",
        "test indices: [1355 1476  367  699  664 1577  177  109  898  305]...\n",
        "train indices: [1534 1400  250 1547 1696 1784   58  728  646  942]...\n",
        "test indices: [1693 1254 1002 1323  870 1567 1233  403  804  978]...\n",
        "train indices: [1100 1363  165 1000  557 1449 1064  641  681  817]...\n",
        "test indices: [1246    7 1476 1431 1414  274 1316 1339 1558 1502]...\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "# TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mean_score(scores, min_=0, max_=1):\n",
      "    \"\"\"Print the mean score and standard 95% Confidence Interval\n",
      "\n",
      "    Assume that the distribution of the scores is normal which\n",
      "    is probably not true when the mean is close to an upper or\n",
      "    lower bound.\n",
      "\n",
      "    For better CI evaluation, use scikits.bootstrap.\n",
      "    \"\"\"\n",
      "    scores = scores.ravel()\n",
      "    m, s = np.mean(scores), np.std(scores)\n",
      "    std_error = s / np.sqrt(scores.shape[0])\n",
      "    ci_min = max(m - 1.96 * std_error, min_)\n",
      "    ci_max = min(m + 1.96 * std_error, max_)\n",
      "    return (\"Mean score: {0:.3f} [{1:.3f} - {2:.3f}]\\n\"\n",
      "            \"Standard deviation: {3:.3f}\").format(\n",
      "        m, ci_min, ci_max, s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise:** \n",
      "\n",
      "- Perform 50 iterations of cross validation with randomly sampled folds of 500 training samples and 500 test samples randomly sampled (use `sklearn.cross_validation.ShuffleSplit`).\n",
      "- Try with `SVC(C=1, gamma=0.01)`\n",
      "- Plot the histogram of the test error 30 bins.\n",
      "- Try to increas the training size\n",
      "- Retry with `SVC(C=10, gamma=0.005)`, then `SVC(C=10, gamma=0.001)` with 500 samples.\n",
      "\n",
      "Hints, type:\n",
      "\n",
      "    from sklearn.cross_validation import ShuffleSplit\n",
      "    ShuffleSplit?  # to read the docstring of the shuffle split\n",
      "    pl.hist?  # to read the docstring of the histogram plot\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = ShuffleSplit(n_samples, n_iter=50, train_size=500, test_size=500)\n",
      "%time scores = cross_val_score(SVC(C=10, gamma=0.005), X, y, cv=cv)\n",
      "_ = pl.hist(scores, range=(0, 1), bins=30)\n",
      "print(mean_score(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.24 s, sys: 0.00 s, total: 4.24 s\n",
        "Wall time: 4.24 s\n",
        "Mean score: 0.900 [0.893 - 0.907]\n",
        "Standard deviation: 0.026"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD9CAYAAABOd5eOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x110d46210>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plotting Learning Curves for Bias-Variance analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_sizes = np.logspace(2, 3, 3).astype(np.int)\n",
      "train_sizes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "array([ 100,  316, 1000])"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parallel Computation of Learning Curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "rc = Client()\n",
      "lv = rc.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for train_size in train_sizes:\n",
      "    cv = ShuffleSplit(n_samples, n_iter=3, train_size=train_size, test_size=500)\n",
      "    for train, test in cv:\n",
      "        # TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([ 100,  316, 1000])"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model Selection with Grid Search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "params = {\n",
      "    'C': np.logspace(-1, 2, 4),\n",
      "    'gamma': np.logspace(-4, 0, 5)[::-1],\n",
      "}\n",
      "pprint(params)\n",
      "print(train_sizes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'C': array([   0.1,    1. ,   10. ,  100. ]),\n",
        " 'gamma': array([  1.00000000e+00,   1.00000000e-01,   1.00000000e-02,\n",
        "         1.00000000e-03,   1.00000000e-04])}\n",
        "[ 100  316 1000]\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "%time gs = GridSearchCV(SVC(), params, n_jobs=-1).fit(X_train[:500], y_train[:500])\n",
      "gs.best_params_, gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 0.09 s, sys: 0.04 s, total: 0.12 s\n",
        "Wall time: 0.87 s\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "({'C': 1.0, 'gamma': 0.001}, 0.96202775172546473)"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Distributed Model Selection with Grid Search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import IterGrid\n",
      "list(IterGrid(params))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "[{'C': 0.10000000000000001, 'gamma': 1.0},\n",
        " {'C': 0.10000000000000001, 'gamma': 0.10000000000000001},\n",
        " {'C': 0.10000000000000001, 'gamma': 0.01},\n",
        " {'C': 0.10000000000000001, 'gamma': 0.001},\n",
        " {'C': 0.10000000000000001, 'gamma': 0.0001},\n",
        " {'C': 1.0, 'gamma': 1.0},\n",
        " {'C': 1.0, 'gamma': 0.10000000000000001},\n",
        " {'C': 1.0, 'gamma': 0.01},\n",
        " {'C': 1.0, 'gamma': 0.001},\n",
        " {'C': 1.0, 'gamma': 0.0001},\n",
        " {'C': 10.0, 'gamma': 1.0},\n",
        " {'C': 10.0, 'gamma': 0.10000000000000001},\n",
        " {'C': 10.0, 'gamma': 0.01},\n",
        " {'C': 10.0, 'gamma': 0.001},\n",
        " {'C': 10.0, 'gamma': 0.0001},\n",
        " {'C': 100.0, 'gamma': 1.0},\n",
        " {'C': 100.0, 'gamma': 0.10000000000000001},\n",
        " {'C': 100.0, 'gamma': 0.01},\n",
        " {'C': 100.0, 'gamma': 0.001},\n",
        " {'C': 100.0, 'gamma': 0.0001}]"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise:** learning curves and grid search\n",
      "\n",
      "- combine the previous examples to compute the learning curves data and grid search in parallel\n",
      "- plot the learning curves of the top 3 models (ranked by high test scores and small durations in case of tie)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}