{
 "metadata": {
  "name": "Model selection and evaluation"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model selection and evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Outline of the session:\n",
      "\n",
      "- Model evaluation without overfitting with Cross-Validation\n",
      "- Hyper parameter tuning and model selection with Grid Search\n",
      "- Error analysis with learning curves and the Bias-Variance trade-off"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "pl.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      },
      {
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x112f7b1d0>"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overfitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overfitting is the problem of learning the training data by heart and being unable to generalize by making correct prediction on new data.\n",
      "\n",
      "Let's load a simple dataset of 8x8 gray level images of handwritten digits:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "digits = load_digits()\n",
      "X, y = digits.data, digits.target\n",
      "print(\"data shape: %r, target shape: %r\" % (X.shape, y.shape))\n",
      "print(\"classes: %r\" % list(np.unique(y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data shape: (1797, 64), target shape: (1797,)\n",
        "classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples, n_features = X.shape\n",
      "print(\"n_samples=%d\" % n_samples)\n",
      "print(\"n_features=%d\" % n_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "n_samples=1797\n",
        "n_features=64\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pl.figure()\n",
      "pl.imshow(X[0].reshape((8, 8)), interpolation='nearest')\n",
      "print(\"Target class: %d\" % y[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Target class: 0\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD5CAYAAAAURMgdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw7ZNUdMxJBoAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x112ca5c50>"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "SVC().fit(X, y).score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Did we really learn a perfect model that can recognize the correct digit class 100% of the time? **Without new data it's impossible to tell.**\n",
      "\n",
      "Let's start again and split the dataset into two random, non overlapping subsets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
      "print(\"train data shape: %r, train target shape: %r\" % (X_train.shape, y_train.shape))\n",
      "print(\"test data shape: %r, test target shape: %r\" % (X_test.shape, y_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train data shape: (1347, 64), train target shape: (1347,)\n",
        "test data shape: (450, 64), test target shape: (450,)\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's retrain a new model on the first subset call the **training set**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC(kernel='rbf').fit(X_train, y_train)\n",
      "train_score = svc.score(X_train, y_train) \n",
      "train_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now compute the performance of the model on new, held out data from the **test set**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_score = svc.score(X_test, y_test)\n",
      "test_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "0.56666666666666665"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This score is clearly not as good as expected! The model cannot generalize so well to new, unseen data.\n",
      "\n",
      "- **Whenever the test data score is not as good as the train score the model is overfitting**\n",
      "\n",
      "- **Whenver the train score is very close to 100% accuracy the model is underfitting**\n",
      "\n",
      "Ideally we want to neither overfit nor underfit: `test_score ~= train_score ~= 1.0`. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- TODO: n_jobs cross validation\n",
      "- TODO: std of test error"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import ShuffleSplit\n",
      "\n",
      "cv = ShuffleSplit(n_samples, n_iter=3, test_size=0.1)\n",
      "for train, test in cv:\n",
      "    print(\"train indices: {0}...\".format(train[:10]))\n",
      "    print(\"test indices: {0}...\".format(test[:10]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train indices: [ 583  582  848 1391  391 1154  862  952  143  498]...\n",
        "test indices: [ 361 1275    7  985 1791  199 1304  221 1599 1680]...\n",
        "train indices: [ 458 1543  738 1224 1123  176 1671  328 1568  281]...\n",
        "test indices: [1394  396  784  806 1556  334 1190  529  889 1651]...\n",
        "train indices: [1271   60  696   70  408  308 1184  693 1359 1732]...\n",
        "test indices: [1141  876 1535 1480  961 1640   32  148  428  300]...\n"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "# TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mean_score(scores, min_=0, max_=1):\n",
      "    \"\"\"Print the mean score and standard 95% Confidence Interval\n",
      "\n",
      "    Assume that the distribution of the scores is normal which\n",
      "    is probably not true when the mean is close to an upper or\n",
      "    lower bound.\n",
      "\n",
      "    For better CI evaluation, use scikits.bootstrap.\n",
      "    \"\"\"\n",
      "    scores = scores.ravel()\n",
      "    m, s = np.mean(scores), np.std(scores)\n",
      "    std_error = s / np.sqrt(scores.shape[0])\n",
      "    ci_min = max(m - 1.96 * std_error, min_)\n",
      "    ci_max = min(m + 1.96 * std_error, max_)\n",
      "    return (\"Mean score: {0:.3f} [{1:.3f} - {2:.3f}]\\n\"\n",
      "            \"Standard deviation: {3:.3f}\").format(\n",
      "        m, ci_min, ci_max, s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise:** \n",
      "\n",
      "- Perform 50 iterations of cross validation with randomly sampled folds of 500 training samples and 500 test samples randomly sampled (use `sklearn.cross_validation.ShuffleSplit`).\n",
      "- Try with `SVC(C=1, gamma=0.01)`\n",
      "- Plot the histogram of the test error 30 bins.\n",
      "- Try to increas the training size\n",
      "- Retry with `SVC(C=10, gamma=0.005)`, then `SVC(C=10, gamma=0.001)` with 500 samples.\n",
      "\n",
      "Hints, type:\n",
      "\n",
      "    from sklearn.cross_validation import ShuffleSplit\n",
      "    ShuffleSplit?  # to read the docstring of the shuffle split\n",
      "    pl.hist?  # to read the docstring of the histogram plot\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = ShuffleSplit(n_samples, n_iter=50, train_size=500, test_size=500)\n",
      "%time scores = cross_val_score(SVC(C=10, gamma=0.005), X, y, cv=cv)\n",
      "print(mean_score(scores))\n",
      "_ = pl.hist(scores, range=(0, 1), bins=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.28 s, sys: 0.01 s, total: 4.29 s\n",
        "Wall time: 4.29 s\n",
        "Mean score: 0.908 [0.901 - 0.916]\n",
        "Standard deviation: 0.027\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD9CAYAAABOd5eOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEOZJREFUeJzt3XtM1fUfx/HXUfhDUwQCjiZsmJcpck0WutIOM8hLEs7m\ndM2RGnNurZl/uG5O9A/Dln8k/uMaGXZxMUtkK6nWPDgvRVO8TM2ck0R2QAmYoZUg398f/sJIPXw5\nnAt8fD42NuQcvuftZ/r0+OF7ztdhWZYlAMCgNiTUAwAA+o+YA4ABiDkAGICYA4ABiDkAGICYA4AB\nvMb8r7/+UlZWltLT05WUlKQ333xTktTS0qKcnBxNmjRJubm5amtrC8qwAID7c/R2nvnNmzc1fPhw\ndXZ26umnn9b777+vyspKxcTEaN26ddqyZYtaW1tVXFwcrJkBAP/R6zbL8OHDJUm3bt3S7du3FRUV\npcrKShUUFEiSCgoKVFFREdgpAQBehfV2h66uLj3xxBO6ePGiVq9eralTp6qpqUlOp1OS5HQ61dTU\n1ON7HA5HYKYFAMP5+qL8Xp+ZDxkyRCdOnNCVK1d08OBBHThwoMftDofjvvG2LIsPy9KGDRtCPsNA\n+WAtWAvWwvtHf9g+m2XUqFGaP3++jh07JqfTqcbGRkmSx+NRXFxcv4YAAPSP15g3Nzd3n6ny559/\n6vvvv1dGRoby8vJUVlYmSSorK1N+fn7gJwUAPJDXPXOPx6OCggJ1dXWpq6tLy5Yt0+zZs5WRkaHF\nixertLRUiYmJKi8vD9a8g47L5Qr1CAMGa3EXa3EXa+EfvZ6a6NNBHY5+7/8AwMOmP+3kFaAAYABi\nDgAGIOYAYABiDgAGIOYAYABiDgAGIOYAYABiDgAGIOYAICkiIrr7jQN7+4iIiA71uPfgFaAAoH/e\nuttutwLTOF4BCgAPOWIOAAYg5gBgAGIOAAYg5gBgAGIOAAYg5gBgAGIOAAYg5gBgAGIOAAYg5gBg\nAGIOAAYg5gBgAGIOAAYg5gBgAGIOAAYg5gBgAGIOAAbwGvP6+nplZ2dr6tSpSk5O1rZt2yRJRUVF\nio+PV0ZGhjIyMlRVVRWUYQEA9+f1GqCNjY1qbGxUenq62tvbNW3aNFVUVKi8vFwjR47U2rVr739Q\nrgEKYJAZ7NcADfN24+jRozV69GhJ0ogRIzRlyhQ1NDRIErEGgAHEa8z/ra6uTrW1tZo+fboOHz6s\nkpIS7dq1S5mZmdq6dasiIyN73L+oqKj7c5fLJZfL5a+ZAcAIbrdbbrfbL8fyus3yj/b2drlcLr3z\nzjvKz8/X1atXFRsbK0lav369PB6PSktL7x6UbRYAg8xg32bpNeYdHR16/vnnNXfuXK1Zs+ae2+vq\n6rRgwQKdPn3aLwMBQCgM9ph7PZvFsiytXLlSSUlJPULu8Xi6P9+7d69SUlJ8enAAgH94fWZ+6NAh\nzZo1S6mpqf//V0vavHmzdu/erRMnTsjhcGjcuHHasWOHnE7n3YPyzBzAIDPYn5nb2jPv80GJOYBB\nZrDHnFeAAoABiDkAGICYA4ABiDkAGICYA4ABiDkAGICYA4ABiDkAGICYA4ABiDkAGICYA4ABiDkA\nGICYA4ABiDkAGICYA4ABiDkAGICYA4ABiDkAGICYA4ABiDkAGICYA4ABiDkAGICYA4ABiDkAGICY\nA4ABiDkAGICYA4ABiDkAGMBrzOvr65Wdna2pU6cqOTlZ27ZtkyS1tLQoJydHkyZNUm5urtra2oIy\nLADg/hyWZVkPurGxsVGNjY1KT09Xe3u7pk2bpoqKCu3cuVMxMTFat26dtmzZotbWVhUXF989qMMh\nL4cFgAHH4XBIstutwDSuP+30+sx89OjRSk9PlySNGDFCU6ZMUUNDgyorK1VQUCBJKigoUEVFhU8P\nDgDwjzC7d6yrq1Ntba2ysrLU1NQkp9MpSXI6nWpqarrn/kVFRd2fu1wuuVyufg8LACZxu91yu91+\nOZbXbZZ/tLe365lnntH69euVn5+vqKgotba2dt8eHR2tlpaWuwdlmwXAIGP0NoskdXR0aNGiRVq2\nbJny8/Ml3Xk23tjYKEnyeDyKi4vz6cEBAP7hNeaWZWnlypVKSkrSmjVrur+el5ensrIySVJZWVl3\n5AEAoeF1m+XQoUOaNWuWUlNT//9fEOndd9/Vk08+qcWLF+vy5ctKTExUeXm5IiMj7x6UbRYAg8xg\n32axtWfe54MScwCDzGCPOa8ABQADEHMAMAAxBwADEHMAMAAxBwADEHMAMAAxBwADEHMAMAAxBwAD\nEHMAMAAxBwADEHMAMAAxBwADEHMAMAAxBwADEHMAMAAxBwADEHMAMAAxBwADEHMAMAAxBwADEHMA\nMAAxBwADEHMAMAAxBwADEHMAMAAxBwADEHMAMIDXmK9YsUJOp1MpKSndXysqKlJ8fLwyMjKUkZGh\nqqqqgA8JAPDOa8yXL19+T6wdDofWrl2r2tpa1dbWas6cOQEdEADQO68xnzlzpqKiou75umVZARsI\nANB3Yb58U0lJiXbt2qXMzExt3bpVkZGR99ynqKio+3OXyyWXy+XrjABgJLfbLbfb7ZdjOaxenmbX\n1dVpwYIFOn36tCTp6tWrio2NlSStX79eHo9HpaWlPQ/qcPDsHcCg4nA4JNntVmAa15929vlslri4\nODkcDjkcDr3yyiuqqanx6YEBAP7T55h7PJ7uz/fu3dvjTBcAQGh43TNfunSpqqur1dzcrISEBG3c\nuFFut1snTpyQw+HQuHHjtGPHjmDNCgB4gF73zH06KHvmAAaZh27PHAAw8BBzADAAMQcAAxBzADAA\nMQcAAxBzADAAMQcAAxBzADAAMQcAAxBzADAAMQcAAxBzADAAMQcAAxBzADAAMQcAAxBzADAAMQcA\nAxBzAMaKiIjuvgB9bx+DHZeNA2Csvl4KjsvGAQBCipgDgAGIOQAYgJgDgAGIOQAYgJgDgAGIOQAY\ngJgDgAGIOQAYwGvMV6xYIafTqZSUlO6vtbS0KCcnR5MmTVJubq7a2toCPiQAwDuvMV++fLmqqqp6\nfK24uFg5OTn69ddfNXv2bBUXFwd0QABA73p9b5a6ujotWLBAp0+fliRNnjxZ1dXVcjqdamxslMvl\n0i+//NLzoLw3C4AB4GF6b5awvn5DU1OTnE6nJMnpdKqpqem+9ysqKur+3OVyyeVy+TQgAJjK7XbL\n7Xb75Vh9fmYeFRWl1tbW7tujo6PV0tLS86A8MwcwADxMz8z7fDbLP9srkuTxeBQXF+fTAwMA/KfP\nMc/Ly1NZWZkkqaysTPn5+X4fCgDQN163WZYuXarq6mo1NzfL6XRq06ZNeuGFF7R48WJdvnxZiYmJ\nKi8vV2RkZM+Dss0CYAB4mLZZuNIQAGM9TDHnFaAAYABiDgAGIOYAYABiDgAGIOYAYABiDgAGIOYA\nYABiDgAGIOYAYABiDgAGIOYAYABiDgAGIOYAYABiDgAGIOYAYABiDgAGIOYAYABiDgB9FiaHw2Hr\nIyIiOigTcdk4AMYK5GXjAnGJOS4bBwAPOWIOAAYg5gBgAGIOAAYg5gBgAGIOAAYg5gBgAGIOAAYg\n5gBgAGIOAAYI8/UbExMTFRERoaFDhyo8PFw1NTX+nAsA0Ac+x9zhcMjtdis6OjhvIgMAeLB+bbPw\nZloAMDD065n5s88+q6FDh2rVqlUqLCzscXtRUVH35y6XSy6Xy9eHAgAjud1uud1uvxzL57fA9Xg8\nGjNmjK5du6acnByVlJRo5syZdw7KW+ACGAB4C1wbxowZI0mKjY3VwoUL+QEoAISQTzG/efOm/vjj\nD0nSjRs39N133yklJcWvgwEA7PNpz7ypqUkLFy6UJHV2duqll15Sbm6uXwcDANjHZeMAGIs9cwDA\noELMAcAAxBwADEDMAcAAxBwADEDMAcAAxBwADEDMAcAAxBwADEDMAcAAxBwADEDMAcAAxBwADEDM\nAcAAxBwADEDMAcAAxBzAoBERES2Hw2H742HClYYADBp9u3KQFMirB3GlIQCA3xFzADAAMQcAAxBz\nADAAMQcAAxBzACHVl9MN8WCcmgggpPp2uiGnJj4Iz8wBwADEHAAMQMwDzO12h3qEAYO1uIu1gL/5\nHPOqqipNnjxZEydO1JYtW/w5k1H4S3sXa3EXawF/8ynmt2/f1quvvqqqqiqdPXtWu3fv1rlz5/w9\nGwDAJp9iXlNTowkTJigxMVHh4eFasmSJ9u3b5+/ZAAA2+XRq4p49e/Ttt9/qww8/lCR9+umn+umn\nn1RSUnLnoJwPCgA+8fXUxDBfvqm3WHOOOQAEl0/bLGPHjlV9fX33r+vr6xUfH++3oQAAfeNTzDMz\nM3XhwgXV1dXp1q1b+uKLL5SXl+fv2QAANvm0zRIWFqbt27frueee0+3bt7Vy5UpNmTLF37MBAGzy\n+TzzuXPn6vz589q+fbvKysq8nm/+2muvaeLEiUpLS1Ntba3Pww50vZ17/9lnnyktLU2pqal66qmn\ndOrUqRBMGRx2X4fw888/KywsTF999VUQpwseO+vgdruVkZGh5ORkuVyu4A4YRL2tRXNzs+bMmaP0\n9HQlJyfr448/Dv6QQbJixQo5nU6lpKQ88D597qbVD52dndb48eOtS5cuWbdu3bLS0tKss2fP9rjP\n119/bc2dO9eyLMv68ccfraysrP485IBlZy2OHDlitbW1WZZlWfv373+o1+Kf+2VnZ1vz58+39uzZ\nE4JJA8vOOrS2tlpJSUlWfX29ZVmWde3atVCMGnB21mLDhg3WG2+8YVnWnXWIjo62Ojo6QjFuwB08\neNA6fvy4lZycfN/bfelmv17Ob+d888rKShUUFEiSsrKy1NbWpqampv487IBkZy1mzJihUaNGSbqz\nFleuXAnFqAFn93UIJSUlevHFFxUbGxuCKQPPzjp8/vnnWrRoUfcJBDExMaEYNeDsrMWYMWN0/fp1\nSdL169f16KOPKizMp53gAW/mzJmKiop64O2+dLNfMW9oaFBCQkL3r+Pj49XQ0NDrfUyMmJ21+LfS\n0lLNmzcvGKMFnd0/F/v27dPq1aslmfnaBDvrcOHCBbW0tCg7O1uZmZn65JNPgj1mUNhZi8LCQp05\nc0aPPfaY0tLS9MEHHwR7zAHDl2726589u38Brf+cd27iX9y+/J4OHDigjz76SIcPHw7gRKFjZy3W\nrFmj4uLi7vdv/u+fERPYWYeOjg4dP35cP/zwg27evKkZM2Zo+vTpmjhxYhAmDB47a7F582alp6fL\n7Xbr4sWLysnJ0cmTJzVy5MggTDjw9LWb/Yq5nfPN/3ufK1euaOzYsf152AHJ7rn3p06dUmFhoaqq\nqrz+N2sws7MWx44d05IlSyTd+cHX/v37FR4ebtQprnbWISEhQTExMRo2bJiGDRumWbNm6eTJk8bF\n3M5aHDlyRG+//bYkafz48Ro3bpzOnz+vzMzMoM46EPjUzf5s4nd0dFiPP/64denSJevvv//u9Qeg\nR48eNfaHfnbW4rfffrPGjx9vHT16NERTBoedtfi3l19+2fryyy+DOGFw2FmHc+fOWbNnz7Y6Ozut\nGzduWMnJydaZM2dCNHHg2FmL119/3SoqKrIsy7IaGxutsWPHWr///nsoxg2KS5cu2foBqN1u9uuZ\n+YPON9+xY4ckadWqVZo3b56++eYbTZgwQY888oh27tzZn4ccsOysxaZNm9Ta2tq9TxweHq6amppQ\njh0QdtbiYWBnHSZPnqw5c+YoNTVVQ4YMUWFhoZKSkkI8uf/ZWYu33npLy5cvV1pamrq6uvTee+8p\nOjo6xJMHxtKlS1VdXa3m5mYlJCRo48aN6ujokOR7NwNyDVAAQHBxpSEAMAAxBwADEHMAMAAxBwAD\nEHMAMAAxBwAD/A8EqlZVbmWITgAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x115328510>"
       ]
      }
     ],
     "prompt_number": 265
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plotting Learning Curves for Bias-Variance analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parallel Computation of Learning Curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}